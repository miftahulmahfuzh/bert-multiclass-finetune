{
  "best_metric": 0.061414919793605804,
  "best_model_checkpoint": "mistralai/Mistral-7B-Instruct-v0.3_20250203_134656/checkpoint-8000",
  "epoch": 2.6899798251513114,
  "eval_steps": 500,
  "global_step": 8000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.03362474781439139,
      "grad_norm": 1.6849302053451538,
      "learning_rate": 4.99226630800269e-05,
      "loss": 1.1533,
      "step": 100
    },
    {
      "epoch": 0.06724949562878278,
      "grad_norm": 0.7497963905334473,
      "learning_rate": 4.983860121049092e-05,
      "loss": 0.1272,
      "step": 200
    },
    {
      "epoch": 0.10087424344317418,
      "grad_norm": 1.268555760383606,
      "learning_rate": 4.9754539340954945e-05,
      "loss": 0.1144,
      "step": 300
    },
    {
      "epoch": 0.13449899125756556,
      "grad_norm": 0.785187840461731,
      "learning_rate": 4.967047747141897e-05,
      "loss": 0.1072,
      "step": 400
    },
    {
      "epoch": 0.16812373907195696,
      "grad_norm": 1.0271438360214233,
      "learning_rate": 4.958641560188299e-05,
      "loss": 0.0982,
      "step": 500
    },
    {
      "epoch": 0.16812373907195696,
      "eval_loss": 0.09536462277173996,
      "eval_runtime": 1414.4949,
      "eval_samples_per_second": 2.911,
      "eval_steps_per_second": 0.728,
      "step": 500
    },
    {
      "epoch": 0.20174848688634836,
      "grad_norm": 1.7619168758392334,
      "learning_rate": 4.950235373234701e-05,
      "loss": 0.0915,
      "step": 600
    },
    {
      "epoch": 0.23537323470073973,
      "grad_norm": 0.741104006767273,
      "learning_rate": 4.941829186281103e-05,
      "loss": 0.0847,
      "step": 700
    },
    {
      "epoch": 0.26899798251513113,
      "grad_norm": 0.9433469772338867,
      "learning_rate": 4.9334229993275055e-05,
      "loss": 0.0792,
      "step": 800
    },
    {
      "epoch": 0.3026227303295225,
      "grad_norm": 1.469007968902588,
      "learning_rate": 4.9250168123739076e-05,
      "loss": 0.0798,
      "step": 900
    },
    {
      "epoch": 0.3362474781439139,
      "grad_norm": 1.173812747001648,
      "learning_rate": 4.91661062542031e-05,
      "loss": 0.0789,
      "step": 1000
    },
    {
      "epoch": 0.3362474781439139,
      "eval_loss": 0.07819588482379913,
      "eval_runtime": 1414.6733,
      "eval_samples_per_second": 2.91,
      "eval_steps_per_second": 0.728,
      "step": 1000
    },
    {
      "epoch": 0.3698722259583053,
      "grad_norm": 1.5632257461547852,
      "learning_rate": 4.908204438466712e-05,
      "loss": 0.0733,
      "step": 1100
    },
    {
      "epoch": 0.4034969737726967,
      "grad_norm": 1.0300445556640625,
      "learning_rate": 4.899798251513114e-05,
      "loss": 0.074,
      "step": 1200
    },
    {
      "epoch": 0.4371217215870881,
      "grad_norm": 1.4359934329986572,
      "learning_rate": 4.8913920645595164e-05,
      "loss": 0.0782,
      "step": 1300
    },
    {
      "epoch": 0.47074646940147946,
      "grad_norm": 0.834077775478363,
      "learning_rate": 4.8829858776059186e-05,
      "loss": 0.0748,
      "step": 1400
    },
    {
      "epoch": 0.5043712172158709,
      "grad_norm": 1.2950022220611572,
      "learning_rate": 4.874579690652321e-05,
      "loss": 0.0722,
      "step": 1500
    },
    {
      "epoch": 0.5043712172158709,
      "eval_loss": 0.07025014609098434,
      "eval_runtime": 1415.0453,
      "eval_samples_per_second": 2.909,
      "eval_steps_per_second": 0.728,
      "step": 1500
    },
    {
      "epoch": 0.5379959650302623,
      "grad_norm": 0.6145228743553162,
      "learning_rate": 4.866173503698723e-05,
      "loss": 0.0719,
      "step": 1600
    },
    {
      "epoch": 0.5716207128446537,
      "grad_norm": 0.5706638693809509,
      "learning_rate": 4.857767316745125e-05,
      "loss": 0.0731,
      "step": 1700
    },
    {
      "epoch": 0.605245460659045,
      "grad_norm": 0.7195777297019958,
      "learning_rate": 4.849361129791527e-05,
      "loss": 0.071,
      "step": 1800
    },
    {
      "epoch": 0.6388702084734365,
      "grad_norm": 1.5740430355072021,
      "learning_rate": 4.840954942837929e-05,
      "loss": 0.0713,
      "step": 1900
    },
    {
      "epoch": 0.6724949562878278,
      "grad_norm": 1.4821792840957642,
      "learning_rate": 4.832548755884331e-05,
      "loss": 0.0738,
      "step": 2000
    },
    {
      "epoch": 0.6724949562878278,
      "eval_loss": 0.06891041249036789,
      "eval_runtime": 1414.947,
      "eval_samples_per_second": 2.91,
      "eval_steps_per_second": 0.728,
      "step": 2000
    },
    {
      "epoch": 0.7061197041022192,
      "grad_norm": 2.3729567527770996,
      "learning_rate": 4.824142568930733e-05,
      "loss": 0.0676,
      "step": 2100
    },
    {
      "epoch": 0.7397444519166106,
      "grad_norm": 0.8823309540748596,
      "learning_rate": 4.8157363819771354e-05,
      "loss": 0.0728,
      "step": 2200
    },
    {
      "epoch": 0.773369199731002,
      "grad_norm": 1.44809889793396,
      "learning_rate": 4.8073301950235376e-05,
      "loss": 0.0704,
      "step": 2300
    },
    {
      "epoch": 0.8069939475453934,
      "grad_norm": 0.510064959526062,
      "learning_rate": 4.79892400806994e-05,
      "loss": 0.0701,
      "step": 2400
    },
    {
      "epoch": 0.8406186953597848,
      "grad_norm": 1.084114909172058,
      "learning_rate": 4.790517821116342e-05,
      "loss": 0.0692,
      "step": 2500
    },
    {
      "epoch": 0.8406186953597848,
      "eval_loss": 0.06761468946933746,
      "eval_runtime": 1414.764,
      "eval_samples_per_second": 2.91,
      "eval_steps_per_second": 0.728,
      "step": 2500
    },
    {
      "epoch": 0.8742434431741762,
      "grad_norm": 0.6189439296722412,
      "learning_rate": 4.782111634162744e-05,
      "loss": 0.0688,
      "step": 2600
    },
    {
      "epoch": 0.9078681909885676,
      "grad_norm": 0.5005658864974976,
      "learning_rate": 4.773705447209146e-05,
      "loss": 0.0662,
      "step": 2700
    },
    {
      "epoch": 0.9414929388029589,
      "grad_norm": 0.7663453817367554,
      "learning_rate": 4.7652992602555485e-05,
      "loss": 0.0674,
      "step": 2800
    },
    {
      "epoch": 0.9751176866173503,
      "grad_norm": 0.7126783728599548,
      "learning_rate": 4.756893073301951e-05,
      "loss": 0.0686,
      "step": 2900
    },
    {
      "epoch": 1.0087424344317417,
      "grad_norm": 1.0605056285858154,
      "learning_rate": 4.748486886348353e-05,
      "loss": 0.0651,
      "step": 3000
    },
    {
      "epoch": 1.0087424344317417,
      "eval_loss": 0.06849712878465652,
      "eval_runtime": 1414.341,
      "eval_samples_per_second": 2.911,
      "eval_steps_per_second": 0.728,
      "step": 3000
    },
    {
      "epoch": 1.0423671822461331,
      "grad_norm": 1.5903892517089844,
      "learning_rate": 4.740080699394755e-05,
      "loss": 0.0648,
      "step": 3100
    },
    {
      "epoch": 1.0759919300605245,
      "grad_norm": 1.4361430406570435,
      "learning_rate": 4.731674512441157e-05,
      "loss": 0.0643,
      "step": 3200
    },
    {
      "epoch": 1.109616677874916,
      "grad_norm": 0.5615174174308777,
      "learning_rate": 4.7232683254875595e-05,
      "loss": 0.0626,
      "step": 3300
    },
    {
      "epoch": 1.1432414256893073,
      "grad_norm": 0.7047272324562073,
      "learning_rate": 4.7148621385339616e-05,
      "loss": 0.0624,
      "step": 3400
    },
    {
      "epoch": 1.1768661735036987,
      "grad_norm": 0.4699445962905884,
      "learning_rate": 4.706455951580364e-05,
      "loss": 0.0633,
      "step": 3500
    },
    {
      "epoch": 1.1768661735036987,
      "eval_loss": 0.0655125305056572,
      "eval_runtime": 1414.5255,
      "eval_samples_per_second": 2.911,
      "eval_steps_per_second": 0.728,
      "step": 3500
    },
    {
      "epoch": 1.21049092131809,
      "grad_norm": 0.7217769622802734,
      "learning_rate": 4.698049764626766e-05,
      "loss": 0.065,
      "step": 3600
    },
    {
      "epoch": 1.2441156691324815,
      "grad_norm": 0.9550502300262451,
      "learning_rate": 4.6896435776731675e-05,
      "loss": 0.0651,
      "step": 3700
    },
    {
      "epoch": 1.277740416946873,
      "grad_norm": 0.8101972937583923,
      "learning_rate": 4.68123739071957e-05,
      "loss": 0.063,
      "step": 3800
    },
    {
      "epoch": 1.3113651647612643,
      "grad_norm": 0.6179037690162659,
      "learning_rate": 4.672831203765972e-05,
      "loss": 0.061,
      "step": 3900
    },
    {
      "epoch": 1.3449899125756557,
      "grad_norm": 0.6317466497421265,
      "learning_rate": 4.664425016812374e-05,
      "loss": 0.0634,
      "step": 4000
    },
    {
      "epoch": 1.3449899125756557,
      "eval_loss": 0.06335790455341339,
      "eval_runtime": 1415.4364,
      "eval_samples_per_second": 2.909,
      "eval_steps_per_second": 0.728,
      "step": 4000
    },
    {
      "epoch": 1.378614660390047,
      "grad_norm": 0.5010823011398315,
      "learning_rate": 4.656018829858776e-05,
      "loss": 0.0615,
      "step": 4100
    },
    {
      "epoch": 1.4122394082044385,
      "grad_norm": 0.863766074180603,
      "learning_rate": 4.6476126429051785e-05,
      "loss": 0.0611,
      "step": 4200
    },
    {
      "epoch": 1.44586415601883,
      "grad_norm": 0.7751241326332092,
      "learning_rate": 4.6392064559515807e-05,
      "loss": 0.0631,
      "step": 4300
    },
    {
      "epoch": 1.4794889038332213,
      "grad_norm": 0.8275595903396606,
      "learning_rate": 4.630800268997983e-05,
      "loss": 0.0598,
      "step": 4400
    },
    {
      "epoch": 1.5131136516476127,
      "grad_norm": 0.6880216598510742,
      "learning_rate": 4.622394082044385e-05,
      "loss": 0.0627,
      "step": 4500
    },
    {
      "epoch": 1.5131136516476127,
      "eval_loss": 0.06408482044935226,
      "eval_runtime": 1415.3853,
      "eval_samples_per_second": 2.909,
      "eval_steps_per_second": 0.728,
      "step": 4500
    },
    {
      "epoch": 1.546738399462004,
      "grad_norm": 0.47994428873062134,
      "learning_rate": 4.613987895090787e-05,
      "loss": 0.0606,
      "step": 4600
    },
    {
      "epoch": 1.5803631472763953,
      "grad_norm": 1.5223579406738281,
      "learning_rate": 4.6055817081371894e-05,
      "loss": 0.0612,
      "step": 4700
    },
    {
      "epoch": 1.6139878950907867,
      "grad_norm": 0.3816652297973633,
      "learning_rate": 4.5971755211835916e-05,
      "loss": 0.0598,
      "step": 4800
    },
    {
      "epoch": 1.647612642905178,
      "grad_norm": 0.6561554670333862,
      "learning_rate": 4.588769334229994e-05,
      "loss": 0.0594,
      "step": 4900
    },
    {
      "epoch": 1.6812373907195695,
      "grad_norm": 1.444551706314087,
      "learning_rate": 4.580363147276396e-05,
      "loss": 0.0608,
      "step": 5000
    },
    {
      "epoch": 1.6812373907195695,
      "eval_loss": 0.0637146383523941,
      "eval_runtime": 1415.3496,
      "eval_samples_per_second": 2.909,
      "eval_steps_per_second": 0.728,
      "step": 5000
    },
    {
      "epoch": 1.7148621385339609,
      "grad_norm": 0.49908342957496643,
      "learning_rate": 4.571956960322798e-05,
      "loss": 0.0622,
      "step": 5100
    },
    {
      "epoch": 1.7484868863483523,
      "grad_norm": 0.6220858097076416,
      "learning_rate": 4.5635507733692003e-05,
      "loss": 0.0598,
      "step": 5200
    },
    {
      "epoch": 1.7821116341627437,
      "grad_norm": 1.091599464416504,
      "learning_rate": 4.5551445864156025e-05,
      "loss": 0.0611,
      "step": 5300
    },
    {
      "epoch": 1.815736381977135,
      "grad_norm": 0.49978259205818176,
      "learning_rate": 4.546738399462005e-05,
      "loss": 0.0629,
      "step": 5400
    },
    {
      "epoch": 1.8493611297915264,
      "grad_norm": 0.6662992835044861,
      "learning_rate": 4.538332212508407e-05,
      "loss": 0.064,
      "step": 5500
    },
    {
      "epoch": 1.8493611297915264,
      "eval_loss": 0.06249693036079407,
      "eval_runtime": 1415.3152,
      "eval_samples_per_second": 2.909,
      "eval_steps_per_second": 0.728,
      "step": 5500
    },
    {
      "epoch": 1.8829858776059178,
      "grad_norm": 0.4155596196651459,
      "learning_rate": 4.5299260255548084e-05,
      "loss": 0.0613,
      "step": 5600
    },
    {
      "epoch": 1.9166106254203092,
      "grad_norm": 0.6822812557220459,
      "learning_rate": 4.5215198386012106e-05,
      "loss": 0.0631,
      "step": 5700
    },
    {
      "epoch": 1.9502353732347006,
      "grad_norm": 0.42287856340408325,
      "learning_rate": 4.513113651647613e-05,
      "loss": 0.0586,
      "step": 5800
    },
    {
      "epoch": 1.983860121049092,
      "grad_norm": 0.5995453596115112,
      "learning_rate": 4.504707464694015e-05,
      "loss": 0.0602,
      "step": 5900
    },
    {
      "epoch": 2.0174848688634834,
      "grad_norm": 1.1248029470443726,
      "learning_rate": 4.496301277740417e-05,
      "loss": 0.0587,
      "step": 6000
    },
    {
      "epoch": 2.0174848688634834,
      "eval_loss": 0.06155605986714363,
      "eval_runtime": 1415.273,
      "eval_samples_per_second": 2.909,
      "eval_steps_per_second": 0.728,
      "step": 6000
    },
    {
      "epoch": 2.051109616677875,
      "grad_norm": 0.8831087350845337,
      "learning_rate": 4.4878950907868194e-05,
      "loss": 0.0566,
      "step": 6100
    },
    {
      "epoch": 2.0847343644922662,
      "grad_norm": 0.7064887881278992,
      "learning_rate": 4.4794889038332215e-05,
      "loss": 0.0544,
      "step": 6200
    },
    {
      "epoch": 2.1183591123066576,
      "grad_norm": 0.9897549748420715,
      "learning_rate": 4.471082716879624e-05,
      "loss": 0.0534,
      "step": 6300
    },
    {
      "epoch": 2.151983860121049,
      "grad_norm": 0.7956385612487793,
      "learning_rate": 4.462676529926026e-05,
      "loss": 0.0538,
      "step": 6400
    },
    {
      "epoch": 2.1856086079354404,
      "grad_norm": 0.9705366492271423,
      "learning_rate": 4.454270342972428e-05,
      "loss": 0.0554,
      "step": 6500
    },
    {
      "epoch": 2.1856086079354404,
      "eval_loss": 0.0646529570221901,
      "eval_runtime": 1415.3491,
      "eval_samples_per_second": 2.909,
      "eval_steps_per_second": 0.728,
      "step": 6500
    },
    {
      "epoch": 2.219233355749832,
      "grad_norm": 1.274084210395813,
      "learning_rate": 4.44586415601883e-05,
      "loss": 0.0569,
      "step": 6600
    },
    {
      "epoch": 2.2528581035642232,
      "grad_norm": 0.6774260997772217,
      "learning_rate": 4.4374579690652325e-05,
      "loss": 0.0525,
      "step": 6700
    },
    {
      "epoch": 2.2864828513786146,
      "grad_norm": 1.3245854377746582,
      "learning_rate": 4.429051782111635e-05,
      "loss": 0.0562,
      "step": 6800
    },
    {
      "epoch": 2.320107599193006,
      "grad_norm": 0.6639735102653503,
      "learning_rate": 4.420645595158037e-05,
      "loss": 0.0548,
      "step": 6900
    },
    {
      "epoch": 2.3537323470073974,
      "grad_norm": 0.8334187269210815,
      "learning_rate": 4.412239408204439e-05,
      "loss": 0.0575,
      "step": 7000
    },
    {
      "epoch": 2.3537323470073974,
      "eval_loss": 0.06250481307506561,
      "eval_runtime": 1415.6294,
      "eval_samples_per_second": 2.908,
      "eval_steps_per_second": 0.728,
      "step": 7000
    },
    {
      "epoch": 2.387357094821789,
      "grad_norm": 0.9183433651924133,
      "learning_rate": 4.403833221250841e-05,
      "loss": 0.0539,
      "step": 7100
    },
    {
      "epoch": 2.42098184263618,
      "grad_norm": 1.0559200048446655,
      "learning_rate": 4.3954270342972434e-05,
      "loss": 0.0556,
      "step": 7200
    },
    {
      "epoch": 2.4546065904505716,
      "grad_norm": 0.8060749769210815,
      "learning_rate": 4.3870208473436456e-05,
      "loss": 0.0526,
      "step": 7300
    },
    {
      "epoch": 2.488231338264963,
      "grad_norm": 1.3032265901565552,
      "learning_rate": 4.378614660390047e-05,
      "loss": 0.0551,
      "step": 7400
    },
    {
      "epoch": 2.5218560860793544,
      "grad_norm": 0.6830941438674927,
      "learning_rate": 4.370208473436449e-05,
      "loss": 0.0559,
      "step": 7500
    },
    {
      "epoch": 2.5218560860793544,
      "eval_loss": 0.06195930019021034,
      "eval_runtime": 1415.2763,
      "eval_samples_per_second": 2.909,
      "eval_steps_per_second": 0.728,
      "step": 7500
    },
    {
      "epoch": 2.555480833893746,
      "grad_norm": 0.8181455731391907,
      "learning_rate": 4.3618022864828515e-05,
      "loss": 0.0531,
      "step": 7600
    },
    {
      "epoch": 2.589105581708137,
      "grad_norm": 0.9641910791397095,
      "learning_rate": 4.353396099529254e-05,
      "loss": 0.0564,
      "step": 7700
    },
    {
      "epoch": 2.6227303295225286,
      "grad_norm": 0.6226714849472046,
      "learning_rate": 4.344989912575656e-05,
      "loss": 0.0518,
      "step": 7800
    },
    {
      "epoch": 2.65635507733692,
      "grad_norm": 0.687961995601654,
      "learning_rate": 4.336583725622058e-05,
      "loss": 0.056,
      "step": 7900
    },
    {
      "epoch": 2.6899798251513114,
      "grad_norm": 0.9533693790435791,
      "learning_rate": 4.32817753866846e-05,
      "loss": 0.0543,
      "step": 8000
    },
    {
      "epoch": 2.6899798251513114,
      "eval_loss": 0.061414919793605804,
      "eval_runtime": 1415.3829,
      "eval_samples_per_second": 2.909,
      "eval_steps_per_second": 0.728,
      "step": 8000
    }
  ],
  "logging_steps": 100,
  "max_steps": 59480,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 20,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 6.995193906887393e+17,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
