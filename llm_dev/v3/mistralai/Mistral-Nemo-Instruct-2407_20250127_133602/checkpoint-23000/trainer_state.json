{
  "best_metric": 0.02593841776251793,
  "best_model_checkpoint": "mistralai/Mistral-Nemo-Instruct-2407_20250127_133602/checkpoint-11500",
  "epoch": 7.73369199731002,
  "eval_steps": 500,
  "global_step": 23000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.03362474781439139,
      "grad_norm": 0.641160786151886,
      "learning_rate": 4.992098184263618e-05,
      "loss": 1.1257,
      "step": 100
    },
    {
      "epoch": 0.06724949562878278,
      "grad_norm": 0.5001724362373352,
      "learning_rate": 4.9836919973100204e-05,
      "loss": 0.0342,
      "step": 200
    },
    {
      "epoch": 0.10087424344317418,
      "grad_norm": 0.27108579874038696,
      "learning_rate": 4.9752858103564226e-05,
      "loss": 0.0283,
      "step": 300
    },
    {
      "epoch": 0.13449899125756556,
      "grad_norm": 0.3886866569519043,
      "learning_rate": 4.966879623402825e-05,
      "loss": 0.0287,
      "step": 400
    },
    {
      "epoch": 0.16812373907195696,
      "grad_norm": 0.2577661871910095,
      "learning_rate": 4.958473436449227e-05,
      "loss": 0.0277,
      "step": 500
    },
    {
      "epoch": 0.16812373907195696,
      "eval_loss": 0.027763938531279564,
      "eval_runtime": 2192.4653,
      "eval_samples_per_second": 1.878,
      "eval_steps_per_second": 0.47,
      "step": 500
    },
    {
      "epoch": 0.20174848688634836,
      "grad_norm": 0.23048444092273712,
      "learning_rate": 4.950067249495629e-05,
      "loss": 0.0268,
      "step": 600
    },
    {
      "epoch": 0.23537323470073973,
      "grad_norm": 0.19538654386997223,
      "learning_rate": 4.941661062542031e-05,
      "loss": 0.0277,
      "step": 700
    },
    {
      "epoch": 0.26899798251513113,
      "grad_norm": 0.2090679258108139,
      "learning_rate": 4.9332548755884335e-05,
      "loss": 0.0269,
      "step": 800
    },
    {
      "epoch": 0.3026227303295225,
      "grad_norm": 0.3309393525123596,
      "learning_rate": 4.924848688634836e-05,
      "loss": 0.0274,
      "step": 900
    },
    {
      "epoch": 0.3362474781439139,
      "grad_norm": 0.19589494168758392,
      "learning_rate": 4.916442501681238e-05,
      "loss": 0.0278,
      "step": 1000
    },
    {
      "epoch": 0.3362474781439139,
      "eval_loss": 0.027354568243026733,
      "eval_runtime": 2192.4732,
      "eval_samples_per_second": 1.878,
      "eval_steps_per_second": 0.47,
      "step": 1000
    },
    {
      "epoch": 0.3698722259583053,
      "grad_norm": 0.20498301088809967,
      "learning_rate": 4.90803631472764e-05,
      "loss": 0.0264,
      "step": 1100
    },
    {
      "epoch": 0.4034969737726967,
      "grad_norm": 0.19685626029968262,
      "learning_rate": 4.899630127774042e-05,
      "loss": 0.0269,
      "step": 1200
    },
    {
      "epoch": 0.4371217215870881,
      "grad_norm": 0.29373177886009216,
      "learning_rate": 4.891223940820444e-05,
      "loss": 0.0282,
      "step": 1300
    },
    {
      "epoch": 0.47074646940147946,
      "grad_norm": 0.19394412636756897,
      "learning_rate": 4.882817753866846e-05,
      "loss": 0.0266,
      "step": 1400
    },
    {
      "epoch": 0.5043712172158709,
      "grad_norm": 0.29366353154182434,
      "learning_rate": 4.874411566913248e-05,
      "loss": 0.0263,
      "step": 1500
    },
    {
      "epoch": 0.5043712172158709,
      "eval_loss": 0.02684774063527584,
      "eval_runtime": 2192.7246,
      "eval_samples_per_second": 1.878,
      "eval_steps_per_second": 0.47,
      "step": 1500
    },
    {
      "epoch": 0.5379959650302623,
      "grad_norm": 0.1639816164970398,
      "learning_rate": 4.8660053799596503e-05,
      "loss": 0.0265,
      "step": 1600
    },
    {
      "epoch": 0.5716207128446537,
      "grad_norm": 0.11305760592222214,
      "learning_rate": 4.8575991930060525e-05,
      "loss": 0.0269,
      "step": 1700
    },
    {
      "epoch": 0.605245460659045,
      "grad_norm": 0.1909124255180359,
      "learning_rate": 4.849193006052455e-05,
      "loss": 0.0272,
      "step": 1800
    },
    {
      "epoch": 0.6388702084734365,
      "grad_norm": 0.23782534897327423,
      "learning_rate": 4.840786819098857e-05,
      "loss": 0.0275,
      "step": 1900
    },
    {
      "epoch": 0.6724949562878278,
      "grad_norm": 0.1830664575099945,
      "learning_rate": 4.832380632145259e-05,
      "loss": 0.027,
      "step": 2000
    },
    {
      "epoch": 0.6724949562878278,
      "eval_loss": 0.026575947180390358,
      "eval_runtime": 2192.3383,
      "eval_samples_per_second": 1.878,
      "eval_steps_per_second": 0.47,
      "step": 2000
    },
    {
      "epoch": 0.7061197041022192,
      "grad_norm": 0.2677260637283325,
      "learning_rate": 4.823974445191661e-05,
      "loss": 0.0264,
      "step": 2100
    },
    {
      "epoch": 0.7397444519166106,
      "grad_norm": 0.2206425815820694,
      "learning_rate": 4.8155682582380635e-05,
      "loss": 0.027,
      "step": 2200
    },
    {
      "epoch": 0.773369199731002,
      "grad_norm": 0.15970540046691895,
      "learning_rate": 4.8071620712844657e-05,
      "loss": 0.0263,
      "step": 2300
    },
    {
      "epoch": 0.8069939475453934,
      "grad_norm": 0.17991675436496735,
      "learning_rate": 4.798755884330868e-05,
      "loss": 0.0275,
      "step": 2400
    },
    {
      "epoch": 0.8406186953597848,
      "grad_norm": 0.1285300850868225,
      "learning_rate": 4.79034969737727e-05,
      "loss": 0.0263,
      "step": 2500
    },
    {
      "epoch": 0.8406186953597848,
      "eval_loss": 0.027360089123249054,
      "eval_runtime": 2192.4003,
      "eval_samples_per_second": 1.878,
      "eval_steps_per_second": 0.47,
      "step": 2500
    },
    {
      "epoch": 0.8742434431741762,
      "grad_norm": 0.12165194004774094,
      "learning_rate": 4.781943510423672e-05,
      "loss": 0.0268,
      "step": 2600
    },
    {
      "epoch": 0.9078681909885676,
      "grad_norm": 0.1593778431415558,
      "learning_rate": 4.7735373234700744e-05,
      "loss": 0.0263,
      "step": 2700
    },
    {
      "epoch": 0.9414929388029589,
      "grad_norm": 0.23292545974254608,
      "learning_rate": 4.7651311365164766e-05,
      "loss": 0.0271,
      "step": 2800
    },
    {
      "epoch": 0.9751176866173503,
      "grad_norm": 0.10912999510765076,
      "learning_rate": 4.756724949562879e-05,
      "loss": 0.0272,
      "step": 2900
    },
    {
      "epoch": 1.0087424344317417,
      "grad_norm": 0.1429692804813385,
      "learning_rate": 4.748318762609281e-05,
      "loss": 0.0265,
      "step": 3000
    },
    {
      "epoch": 1.0087424344317417,
      "eval_loss": 0.026500597596168518,
      "eval_runtime": 2191.8529,
      "eval_samples_per_second": 1.878,
      "eval_steps_per_second": 0.47,
      "step": 3000
    },
    {
      "epoch": 1.0423671822461331,
      "grad_norm": 0.20607545971870422,
      "learning_rate": 4.7399125756556825e-05,
      "loss": 0.0275,
      "step": 3100
    },
    {
      "epoch": 1.0759919300605245,
      "grad_norm": 0.1046142429113388,
      "learning_rate": 4.731506388702085e-05,
      "loss": 0.0264,
      "step": 3200
    },
    {
      "epoch": 1.109616677874916,
      "grad_norm": 0.21291977167129517,
      "learning_rate": 4.723100201748487e-05,
      "loss": 0.0274,
      "step": 3300
    },
    {
      "epoch": 1.1432414256893073,
      "grad_norm": 0.12833045423030853,
      "learning_rate": 4.714694014794889e-05,
      "loss": 0.0261,
      "step": 3400
    },
    {
      "epoch": 1.1768661735036987,
      "grad_norm": 0.13565319776535034,
      "learning_rate": 4.706287827841291e-05,
      "loss": 0.0262,
      "step": 3500
    },
    {
      "epoch": 1.1768661735036987,
      "eval_loss": 0.026306092739105225,
      "eval_runtime": 2192.3688,
      "eval_samples_per_second": 1.878,
      "eval_steps_per_second": 0.47,
      "step": 3500
    },
    {
      "epoch": 1.21049092131809,
      "grad_norm": 0.14196908473968506,
      "learning_rate": 4.6978816408876934e-05,
      "loss": 0.0265,
      "step": 3600
    },
    {
      "epoch": 1.2441156691324815,
      "grad_norm": 0.21494944393634796,
      "learning_rate": 4.6894754539340956e-05,
      "loss": 0.0268,
      "step": 3700
    },
    {
      "epoch": 1.277740416946873,
      "grad_norm": 0.18145109713077545,
      "learning_rate": 4.681069266980498e-05,
      "loss": 0.0269,
      "step": 3800
    },
    {
      "epoch": 1.3113651647612643,
      "grad_norm": 0.1316331923007965,
      "learning_rate": 4.6726630800269e-05,
      "loss": 0.0262,
      "step": 3900
    },
    {
      "epoch": 1.3449899125756557,
      "grad_norm": 0.18663345277309418,
      "learning_rate": 4.664256893073302e-05,
      "loss": 0.0272,
      "step": 4000
    },
    {
      "epoch": 1.3449899125756557,
      "eval_loss": 0.0264876838773489,
      "eval_runtime": 2192.4351,
      "eval_samples_per_second": 1.878,
      "eval_steps_per_second": 0.47,
      "step": 4000
    },
    {
      "epoch": 1.378614660390047,
      "grad_norm": 0.1402311474084854,
      "learning_rate": 4.6558507061197044e-05,
      "loss": 0.0252,
      "step": 4100
    },
    {
      "epoch": 1.4122394082044385,
      "grad_norm": 0.07758776098489761,
      "learning_rate": 4.6474445191661065e-05,
      "loss": 0.0265,
      "step": 4200
    },
    {
      "epoch": 1.44586415601883,
      "grad_norm": 0.1768583506345749,
      "learning_rate": 4.639038332212509e-05,
      "loss": 0.0278,
      "step": 4300
    },
    {
      "epoch": 1.4794889038332213,
      "grad_norm": 0.12287817895412445,
      "learning_rate": 4.630632145258911e-05,
      "loss": 0.0253,
      "step": 4400
    },
    {
      "epoch": 1.5131136516476127,
      "grad_norm": 0.1156153529882431,
      "learning_rate": 4.622225958305313e-05,
      "loss": 0.0275,
      "step": 4500
    },
    {
      "epoch": 1.5131136516476127,
      "eval_loss": 0.026322519406676292,
      "eval_runtime": 2191.9651,
      "eval_samples_per_second": 1.878,
      "eval_steps_per_second": 0.47,
      "step": 4500
    },
    {
      "epoch": 1.546738399462004,
      "grad_norm": 0.23380689322948456,
      "learning_rate": 4.613819771351715e-05,
      "loss": 0.0259,
      "step": 4600
    },
    {
      "epoch": 1.5803631472763953,
      "grad_norm": 0.13502661883831024,
      "learning_rate": 4.6054135843981175e-05,
      "loss": 0.0264,
      "step": 4700
    },
    {
      "epoch": 1.6139878950907867,
      "grad_norm": 0.10481362789869308,
      "learning_rate": 4.59700739744452e-05,
      "loss": 0.0265,
      "step": 4800
    },
    {
      "epoch": 1.647612642905178,
      "grad_norm": 0.14020827412605286,
      "learning_rate": 4.588601210490921e-05,
      "loss": 0.0257,
      "step": 4900
    },
    {
      "epoch": 1.6812373907195695,
      "grad_norm": 0.11887529492378235,
      "learning_rate": 4.5801950235373234e-05,
      "loss": 0.0255,
      "step": 5000
    },
    {
      "epoch": 1.6812373907195695,
      "eval_loss": 0.026661477982997894,
      "eval_runtime": 2192.8148,
      "eval_samples_per_second": 1.877,
      "eval_steps_per_second": 0.47,
      "step": 5000
    },
    {
      "epoch": 1.7148621385339609,
      "grad_norm": 0.14070995151996613,
      "learning_rate": 4.5717888365837255e-05,
      "loss": 0.0255,
      "step": 5100
    },
    {
      "epoch": 1.7484868863483523,
      "grad_norm": 0.09499962627887726,
      "learning_rate": 4.563382649630128e-05,
      "loss": 0.0266,
      "step": 5200
    },
    {
      "epoch": 1.7821116341627437,
      "grad_norm": 0.13643738627433777,
      "learning_rate": 4.55497646267653e-05,
      "loss": 0.0271,
      "step": 5300
    },
    {
      "epoch": 1.815736381977135,
      "grad_norm": 0.12008057534694672,
      "learning_rate": 4.546570275722932e-05,
      "loss": 0.0269,
      "step": 5400
    },
    {
      "epoch": 1.8493611297915264,
      "grad_norm": 0.10218573361635208,
      "learning_rate": 4.538164088769334e-05,
      "loss": 0.0276,
      "step": 5500
    },
    {
      "epoch": 1.8493611297915264,
      "eval_loss": 0.026569955050945282,
      "eval_runtime": 2192.2533,
      "eval_samples_per_second": 1.878,
      "eval_steps_per_second": 0.47,
      "step": 5500
    },
    {
      "epoch": 1.8829858776059178,
      "grad_norm": 0.1134338527917862,
      "learning_rate": 4.5297579018157365e-05,
      "loss": 0.0267,
      "step": 5600
    },
    {
      "epoch": 1.9166106254203092,
      "grad_norm": 0.0923151969909668,
      "learning_rate": 4.521351714862139e-05,
      "loss": 0.0265,
      "step": 5700
    },
    {
      "epoch": 1.9502353732347006,
      "grad_norm": 0.09816635400056839,
      "learning_rate": 4.512945527908541e-05,
      "loss": 0.026,
      "step": 5800
    },
    {
      "epoch": 1.983860121049092,
      "grad_norm": 0.11389204114675522,
      "learning_rate": 4.504539340954943e-05,
      "loss": 0.0276,
      "step": 5900
    },
    {
      "epoch": 2.0174848688634834,
      "grad_norm": 0.07684340327978134,
      "learning_rate": 4.496133154001345e-05,
      "loss": 0.0265,
      "step": 6000
    },
    {
      "epoch": 2.0174848688634834,
      "eval_loss": 0.026240721344947815,
      "eval_runtime": 2192.4228,
      "eval_samples_per_second": 1.878,
      "eval_steps_per_second": 0.47,
      "step": 6000
    },
    {
      "epoch": 2.051109616677875,
      "grad_norm": 0.10372278094291687,
      "learning_rate": 4.4877269670477474e-05,
      "loss": 0.0269,
      "step": 6100
    },
    {
      "epoch": 2.0847343644922662,
      "grad_norm": 0.12303819507360458,
      "learning_rate": 4.4793207800941496e-05,
      "loss": 0.0255,
      "step": 6200
    },
    {
      "epoch": 2.1183591123066576,
      "grad_norm": 0.12709005177021027,
      "learning_rate": 4.470914593140552e-05,
      "loss": 0.0258,
      "step": 6300
    },
    {
      "epoch": 2.151983860121049,
      "grad_norm": 0.07869327813386917,
      "learning_rate": 4.462508406186954e-05,
      "loss": 0.0262,
      "step": 6400
    },
    {
      "epoch": 2.1856086079354404,
      "grad_norm": 0.17674118280410767,
      "learning_rate": 4.454102219233356e-05,
      "loss": 0.026,
      "step": 6500
    },
    {
      "epoch": 2.1856086079354404,
      "eval_loss": 0.026347648352384567,
      "eval_runtime": 2192.9052,
      "eval_samples_per_second": 1.877,
      "eval_steps_per_second": 0.47,
      "step": 6500
    },
    {
      "epoch": 2.219233355749832,
      "grad_norm": 0.113501638174057,
      "learning_rate": 4.4456960322797584e-05,
      "loss": 0.0266,
      "step": 6600
    },
    {
      "epoch": 2.2528581035642232,
      "grad_norm": 0.09660324454307556,
      "learning_rate": 4.4372898453261605e-05,
      "loss": 0.0268,
      "step": 6700
    },
    {
      "epoch": 2.2864828513786146,
      "grad_norm": 0.11121663451194763,
      "learning_rate": 4.428883658372562e-05,
      "loss": 0.0266,
      "step": 6800
    },
    {
      "epoch": 2.320107599193006,
      "grad_norm": 0.07921332865953445,
      "learning_rate": 4.420477471418964e-05,
      "loss": 0.0271,
      "step": 6900
    },
    {
      "epoch": 2.3537323470073974,
      "grad_norm": 0.07500557601451874,
      "learning_rate": 4.4120712844653664e-05,
      "loss": 0.0275,
      "step": 7000
    },
    {
      "epoch": 2.3537323470073974,
      "eval_loss": 0.026391208171844482,
      "eval_runtime": 2192.5273,
      "eval_samples_per_second": 1.878,
      "eval_steps_per_second": 0.47,
      "step": 7000
    },
    {
      "epoch": 2.387357094821789,
      "grad_norm": 0.09904318302869797,
      "learning_rate": 4.4036650975117686e-05,
      "loss": 0.0267,
      "step": 7100
    },
    {
      "epoch": 2.42098184263618,
      "grad_norm": 0.09968884289264679,
      "learning_rate": 4.395258910558171e-05,
      "loss": 0.026,
      "step": 7200
    },
    {
      "epoch": 2.4546065904505716,
      "grad_norm": 0.1820349544286728,
      "learning_rate": 4.386852723604573e-05,
      "loss": 0.0251,
      "step": 7300
    },
    {
      "epoch": 2.488231338264963,
      "grad_norm": 0.12551140785217285,
      "learning_rate": 4.378446536650975e-05,
      "loss": 0.0263,
      "step": 7400
    },
    {
      "epoch": 2.5218560860793544,
      "grad_norm": 0.17216499149799347,
      "learning_rate": 4.3700403496973774e-05,
      "loss": 0.0269,
      "step": 7500
    },
    {
      "epoch": 2.5218560860793544,
      "eval_loss": 0.02659681625664234,
      "eval_runtime": 2192.5104,
      "eval_samples_per_second": 1.878,
      "eval_steps_per_second": 0.47,
      "step": 7500
    },
    {
      "epoch": 2.555480833893746,
      "grad_norm": 0.0723830834031105,
      "learning_rate": 4.3616341627437796e-05,
      "loss": 0.0256,
      "step": 7600
    },
    {
      "epoch": 2.589105581708137,
      "grad_norm": 0.11468777060508728,
      "learning_rate": 4.353227975790182e-05,
      "loss": 0.0268,
      "step": 7700
    },
    {
      "epoch": 2.6227303295225286,
      "grad_norm": 0.13840582966804504,
      "learning_rate": 4.344821788836584e-05,
      "loss": 0.0251,
      "step": 7800
    },
    {
      "epoch": 2.65635507733692,
      "grad_norm": 0.10273584723472595,
      "learning_rate": 4.336415601882986e-05,
      "loss": 0.027,
      "step": 7900
    },
    {
      "epoch": 2.6899798251513114,
      "grad_norm": 0.09140454232692719,
      "learning_rate": 4.328009414929388e-05,
      "loss": 0.0262,
      "step": 8000
    },
    {
      "epoch": 2.6899798251513114,
      "eval_loss": 0.026367973536252975,
      "eval_runtime": 2192.0391,
      "eval_samples_per_second": 1.878,
      "eval_steps_per_second": 0.47,
      "step": 8000
    },
    {
      "epoch": 2.723604572965703,
      "grad_norm": 0.11577794700860977,
      "learning_rate": 4.3196032279757905e-05,
      "loss": 0.0261,
      "step": 8100
    },
    {
      "epoch": 2.757229320780094,
      "grad_norm": 0.11418697983026505,
      "learning_rate": 4.311197041022193e-05,
      "loss": 0.0266,
      "step": 8200
    },
    {
      "epoch": 2.7908540685944856,
      "grad_norm": 0.10088880360126495,
      "learning_rate": 4.302790854068595e-05,
      "loss": 0.0259,
      "step": 8300
    },
    {
      "epoch": 2.824478816408877,
      "grad_norm": 0.09994824975728989,
      "learning_rate": 4.294384667114997e-05,
      "loss": 0.0255,
      "step": 8400
    },
    {
      "epoch": 2.8581035642232684,
      "grad_norm": 0.10596463084220886,
      "learning_rate": 4.285978480161399e-05,
      "loss": 0.0268,
      "step": 8500
    },
    {
      "epoch": 2.8581035642232684,
      "eval_loss": 0.026176907122135162,
      "eval_runtime": 2192.6522,
      "eval_samples_per_second": 1.878,
      "eval_steps_per_second": 0.47,
      "step": 8500
    },
    {
      "epoch": 2.89172831203766,
      "grad_norm": 0.08060269057750702,
      "learning_rate": 4.277572293207801e-05,
      "loss": 0.0262,
      "step": 8600
    },
    {
      "epoch": 2.925353059852051,
      "grad_norm": 0.10241471976041794,
      "learning_rate": 4.269166106254203e-05,
      "loss": 0.0269,
      "step": 8700
    },
    {
      "epoch": 2.9589778076664426,
      "grad_norm": 0.08059334754943848,
      "learning_rate": 4.260759919300605e-05,
      "loss": 0.027,
      "step": 8800
    },
    {
      "epoch": 2.992602555480834,
      "grad_norm": 0.11221513152122498,
      "learning_rate": 4.252353732347007e-05,
      "loss": 0.0254,
      "step": 8900
    },
    {
      "epoch": 3.0262273032952254,
      "grad_norm": 0.1491355001926422,
      "learning_rate": 4.2439475453934095e-05,
      "loss": 0.0265,
      "step": 9000
    },
    {
      "epoch": 3.0262273032952254,
      "eval_loss": 0.02625347673892975,
      "eval_runtime": 2192.6834,
      "eval_samples_per_second": 1.878,
      "eval_steps_per_second": 0.47,
      "step": 9000
    },
    {
      "epoch": 3.0598520511096168,
      "grad_norm": 0.07609028369188309,
      "learning_rate": 4.235541358439812e-05,
      "loss": 0.026,
      "step": 9100
    },
    {
      "epoch": 3.093476798924008,
      "grad_norm": 0.11626427620649338,
      "learning_rate": 4.227135171486214e-05,
      "loss": 0.0268,
      "step": 9200
    },
    {
      "epoch": 3.1271015467383996,
      "grad_norm": 0.09955122321844101,
      "learning_rate": 4.218728984532616e-05,
      "loss": 0.0268,
      "step": 9300
    },
    {
      "epoch": 3.160726294552791,
      "grad_norm": 0.09756293892860413,
      "learning_rate": 4.210322797579018e-05,
      "loss": 0.0263,
      "step": 9400
    },
    {
      "epoch": 3.1943510423671824,
      "grad_norm": 0.08513397723436356,
      "learning_rate": 4.2019166106254204e-05,
      "loss": 0.026,
      "step": 9500
    },
    {
      "epoch": 3.1943510423671824,
      "eval_loss": 0.026211341843008995,
      "eval_runtime": 2193.0541,
      "eval_samples_per_second": 1.877,
      "eval_steps_per_second": 0.47,
      "step": 9500
    },
    {
      "epoch": 3.2279757901815738,
      "grad_norm": 0.08176302909851074,
      "learning_rate": 4.1935104236718226e-05,
      "loss": 0.0262,
      "step": 9600
    },
    {
      "epoch": 3.261600537995965,
      "grad_norm": 0.1372072547674179,
      "learning_rate": 4.185104236718225e-05,
      "loss": 0.0271,
      "step": 9700
    },
    {
      "epoch": 3.2952252858103566,
      "grad_norm": 0.09025067090988159,
      "learning_rate": 4.176698049764627e-05,
      "loss": 0.0263,
      "step": 9800
    },
    {
      "epoch": 3.328850033624748,
      "grad_norm": 0.08269008249044418,
      "learning_rate": 4.168291862811029e-05,
      "loss": 0.0255,
      "step": 9900
    },
    {
      "epoch": 3.3624747814391394,
      "grad_norm": 0.13479496538639069,
      "learning_rate": 4.1598856758574314e-05,
      "loss": 0.0268,
      "step": 10000
    },
    {
      "epoch": 3.3624747814391394,
      "eval_loss": 0.026189744472503662,
      "eval_runtime": 2193.0213,
      "eval_samples_per_second": 1.877,
      "eval_steps_per_second": 0.47,
      "step": 10000
    },
    {
      "epoch": 3.3960995292535308,
      "grad_norm": 0.05816490203142166,
      "learning_rate": 4.1514794889038336e-05,
      "loss": 0.026,
      "step": 10100
    },
    {
      "epoch": 3.429724277067922,
      "grad_norm": 0.10785482078790665,
      "learning_rate": 4.143073301950236e-05,
      "loss": 0.0262,
      "step": 10200
    },
    {
      "epoch": 3.4633490248823136,
      "grad_norm": 0.10899050533771515,
      "learning_rate": 4.134667114996638e-05,
      "loss": 0.0267,
      "step": 10300
    },
    {
      "epoch": 3.496973772696705,
      "grad_norm": 0.10196287930011749,
      "learning_rate": 4.1262609280430394e-05,
      "loss": 0.0258,
      "step": 10400
    },
    {
      "epoch": 3.530598520511096,
      "grad_norm": 0.09878555685281754,
      "learning_rate": 4.1178547410894416e-05,
      "loss": 0.0256,
      "step": 10500
    },
    {
      "epoch": 3.530598520511096,
      "eval_loss": 0.02615259774029255,
      "eval_runtime": 2192.7299,
      "eval_samples_per_second": 1.878,
      "eval_steps_per_second": 0.47,
      "step": 10500
    },
    {
      "epoch": 3.5642232683254873,
      "grad_norm": 0.1127917692065239,
      "learning_rate": 4.109448554135844e-05,
      "loss": 0.026,
      "step": 10600
    },
    {
      "epoch": 3.5978480161398787,
      "grad_norm": 0.08391498774290085,
      "learning_rate": 4.101042367182246e-05,
      "loss": 0.0265,
      "step": 10700
    },
    {
      "epoch": 3.63147276395427,
      "grad_norm": 0.1638464629650116,
      "learning_rate": 4.092636180228648e-05,
      "loss": 0.0258,
      "step": 10800
    },
    {
      "epoch": 3.6650975117686615,
      "grad_norm": 0.07078135758638382,
      "learning_rate": 4.0842299932750504e-05,
      "loss": 0.0271,
      "step": 10900
    },
    {
      "epoch": 3.698722259583053,
      "grad_norm": 0.06283584982156754,
      "learning_rate": 4.0758238063214526e-05,
      "loss": 0.0259,
      "step": 11000
    },
    {
      "epoch": 3.698722259583053,
      "eval_loss": 0.026195673272013664,
      "eval_runtime": 2191.3667,
      "eval_samples_per_second": 1.879,
      "eval_steps_per_second": 0.47,
      "step": 11000
    },
    {
      "epoch": 3.7323470073974443,
      "grad_norm": 0.05980030447244644,
      "learning_rate": 4.067417619367855e-05,
      "loss": 0.0253,
      "step": 11100
    },
    {
      "epoch": 3.7659717552118357,
      "grad_norm": 0.08919291198253632,
      "learning_rate": 4.059011432414257e-05,
      "loss": 0.0266,
      "step": 11200
    },
    {
      "epoch": 3.799596503026227,
      "grad_norm": 0.11170770227909088,
      "learning_rate": 4.050605245460659e-05,
      "loss": 0.0258,
      "step": 11300
    },
    {
      "epoch": 3.8332212508406185,
      "grad_norm": 0.16678763926029205,
      "learning_rate": 4.042199058507061e-05,
      "loss": 0.0261,
      "step": 11400
    },
    {
      "epoch": 3.86684599865501,
      "grad_norm": 0.09004098922014236,
      "learning_rate": 4.0337928715534635e-05,
      "loss": 0.0264,
      "step": 11500
    },
    {
      "epoch": 3.86684599865501,
      "eval_loss": 0.02593841776251793,
      "eval_runtime": 2192.0582,
      "eval_samples_per_second": 1.878,
      "eval_steps_per_second": 0.47,
      "step": 11500
    },
    {
      "epoch": 3.9004707464694013,
      "grad_norm": 0.1251124143600464,
      "learning_rate": 4.025386684599866e-05,
      "loss": 0.0266,
      "step": 11600
    },
    {
      "epoch": 3.9340954942837927,
      "grad_norm": 0.07556796818971634,
      "learning_rate": 4.016980497646268e-05,
      "loss": 0.0256,
      "step": 11700
    },
    {
      "epoch": 3.967720242098184,
      "grad_norm": 0.0687950924038887,
      "learning_rate": 4.00857431069267e-05,
      "loss": 0.0264,
      "step": 11800
    },
    {
      "epoch": 4.0013449899125755,
      "grad_norm": 0.08315372467041016,
      "learning_rate": 4.000168123739072e-05,
      "loss": 0.0263,
      "step": 11900
    },
    {
      "epoch": 4.034969737726967,
      "grad_norm": 0.07128195464611053,
      "learning_rate": 3.9917619367854744e-05,
      "loss": 0.0268,
      "step": 12000
    },
    {
      "epoch": 4.034969737726967,
      "eval_loss": 0.026087120175361633,
      "eval_runtime": 2192.774,
      "eval_samples_per_second": 1.878,
      "eval_steps_per_second": 0.47,
      "step": 12000
    },
    {
      "epoch": 4.068594485541358,
      "grad_norm": 0.10070999711751938,
      "learning_rate": 3.9833557498318766e-05,
      "loss": 0.0258,
      "step": 12100
    },
    {
      "epoch": 4.10221923335575,
      "grad_norm": 0.09584000706672668,
      "learning_rate": 3.974949562878278e-05,
      "loss": 0.0266,
      "step": 12200
    },
    {
      "epoch": 4.135843981170141,
      "grad_norm": 0.07915695756673813,
      "learning_rate": 3.96654337592468e-05,
      "loss": 0.0267,
      "step": 12300
    },
    {
      "epoch": 4.1694687289845325,
      "grad_norm": 0.08043750375509262,
      "learning_rate": 3.9581371889710825e-05,
      "loss": 0.0258,
      "step": 12400
    },
    {
      "epoch": 4.203093476798924,
      "grad_norm": 0.14320191740989685,
      "learning_rate": 3.949731002017485e-05,
      "loss": 0.026,
      "step": 12500
    },
    {
      "epoch": 4.203093476798924,
      "eval_loss": 0.026381151750683784,
      "eval_runtime": 2192.7246,
      "eval_samples_per_second": 1.878,
      "eval_steps_per_second": 0.47,
      "step": 12500
    },
    {
      "epoch": 4.236718224613315,
      "grad_norm": 0.11161890625953674,
      "learning_rate": 3.941324815063887e-05,
      "loss": 0.0261,
      "step": 12600
    },
    {
      "epoch": 4.270342972427707,
      "grad_norm": 0.09397635608911514,
      "learning_rate": 3.932918628110289e-05,
      "loss": 0.026,
      "step": 12700
    },
    {
      "epoch": 4.303967720242098,
      "grad_norm": 0.08136659860610962,
      "learning_rate": 3.924512441156691e-05,
      "loss": 0.0252,
      "step": 12800
    },
    {
      "epoch": 4.3375924680564895,
      "grad_norm": 0.13841158151626587,
      "learning_rate": 3.9161062542030935e-05,
      "loss": 0.0268,
      "step": 12900
    },
    {
      "epoch": 4.371217215870881,
      "grad_norm": 0.10071076452732086,
      "learning_rate": 3.9077000672494956e-05,
      "loss": 0.026,
      "step": 13000
    },
    {
      "epoch": 4.371217215870881,
      "eval_loss": 0.026341404765844345,
      "eval_runtime": 2192.8617,
      "eval_samples_per_second": 1.877,
      "eval_steps_per_second": 0.47,
      "step": 13000
    },
    {
      "epoch": 4.404841963685272,
      "grad_norm": 0.07374011725187302,
      "learning_rate": 3.899293880295898e-05,
      "loss": 0.0264,
      "step": 13100
    },
    {
      "epoch": 4.438466711499664,
      "grad_norm": 0.06959843635559082,
      "learning_rate": 3.8908876933423e-05,
      "loss": 0.0261,
      "step": 13200
    },
    {
      "epoch": 4.472091459314055,
      "grad_norm": 0.08466912806034088,
      "learning_rate": 3.882481506388702e-05,
      "loss": 0.027,
      "step": 13300
    },
    {
      "epoch": 4.5057162071284464,
      "grad_norm": 0.11419077217578888,
      "learning_rate": 3.8740753194351044e-05,
      "loss": 0.0268,
      "step": 13400
    },
    {
      "epoch": 4.539340954942838,
      "grad_norm": 0.11229173839092255,
      "learning_rate": 3.8656691324815066e-05,
      "loss": 0.0263,
      "step": 13500
    },
    {
      "epoch": 4.539340954942838,
      "eval_loss": 0.02609800174832344,
      "eval_runtime": 2192.101,
      "eval_samples_per_second": 1.878,
      "eval_steps_per_second": 0.47,
      "step": 13500
    },
    {
      "epoch": 4.572965702757229,
      "grad_norm": 0.07671544700860977,
      "learning_rate": 3.857262945527909e-05,
      "loss": 0.0256,
      "step": 13600
    },
    {
      "epoch": 4.606590450571621,
      "grad_norm": 0.0642695277929306,
      "learning_rate": 3.848856758574311e-05,
      "loss": 0.0266,
      "step": 13700
    },
    {
      "epoch": 4.640215198386012,
      "grad_norm": 0.09531751275062561,
      "learning_rate": 3.840450571620713e-05,
      "loss": 0.0269,
      "step": 13800
    },
    {
      "epoch": 4.673839946200403,
      "grad_norm": 0.1496979147195816,
      "learning_rate": 3.832044384667115e-05,
      "loss": 0.0259,
      "step": 13900
    },
    {
      "epoch": 4.707464694014795,
      "grad_norm": 0.08056020736694336,
      "learning_rate": 3.823638197713517e-05,
      "loss": 0.0261,
      "step": 14000
    },
    {
      "epoch": 4.707464694014795,
      "eval_loss": 0.026433885097503662,
      "eval_runtime": 2192.7197,
      "eval_samples_per_second": 1.878,
      "eval_steps_per_second": 0.47,
      "step": 14000
    },
    {
      "epoch": 4.741089441829186,
      "grad_norm": 0.06194904074072838,
      "learning_rate": 3.815232010759919e-05,
      "loss": 0.0261,
      "step": 14100
    },
    {
      "epoch": 4.774714189643578,
      "grad_norm": 0.07358953356742859,
      "learning_rate": 3.806825823806321e-05,
      "loss": 0.0256,
      "step": 14200
    },
    {
      "epoch": 4.808338937457969,
      "grad_norm": 0.07365865260362625,
      "learning_rate": 3.7984196368527234e-05,
      "loss": 0.0253,
      "step": 14300
    },
    {
      "epoch": 4.84196368527236,
      "grad_norm": 0.09300699084997177,
      "learning_rate": 3.7900134498991256e-05,
      "loss": 0.0257,
      "step": 14400
    },
    {
      "epoch": 4.875588433086752,
      "grad_norm": 0.08737151324748993,
      "learning_rate": 3.781607262945528e-05,
      "loss": 0.0265,
      "step": 14500
    },
    {
      "epoch": 4.875588433086752,
      "eval_loss": 0.026052474975585938,
      "eval_runtime": 2192.6142,
      "eval_samples_per_second": 1.878,
      "eval_steps_per_second": 0.47,
      "step": 14500
    },
    {
      "epoch": 4.909213180901143,
      "grad_norm": 0.0936155915260315,
      "learning_rate": 3.77320107599193e-05,
      "loss": 0.0254,
      "step": 14600
    },
    {
      "epoch": 4.942837928715535,
      "grad_norm": 0.07242726534605026,
      "learning_rate": 3.764794889038332e-05,
      "loss": 0.0253,
      "step": 14700
    },
    {
      "epoch": 4.976462676529926,
      "grad_norm": 0.08457030355930328,
      "learning_rate": 3.756388702084734e-05,
      "loss": 0.0262,
      "step": 14800
    },
    {
      "epoch": 5.010087424344317,
      "grad_norm": 0.09259510785341263,
      "learning_rate": 3.7479825151311365e-05,
      "loss": 0.0261,
      "step": 14900
    },
    {
      "epoch": 5.043712172158709,
      "grad_norm": 0.09639555960893631,
      "learning_rate": 3.739576328177539e-05,
      "loss": 0.0259,
      "step": 15000
    },
    {
      "epoch": 5.043712172158709,
      "eval_loss": 0.026188068091869354,
      "eval_runtime": 2193.4559,
      "eval_samples_per_second": 1.877,
      "eval_steps_per_second": 0.47,
      "step": 15000
    },
    {
      "epoch": 5.0773369199731,
      "grad_norm": 0.10708359628915787,
      "learning_rate": 3.731170141223941e-05,
      "loss": 0.0266,
      "step": 15100
    },
    {
      "epoch": 5.110961667787492,
      "grad_norm": 0.09715698659420013,
      "learning_rate": 3.722763954270343e-05,
      "loss": 0.0263,
      "step": 15200
    },
    {
      "epoch": 5.144586415601883,
      "grad_norm": 0.09757163375616074,
      "learning_rate": 3.714357767316745e-05,
      "loss": 0.0263,
      "step": 15300
    },
    {
      "epoch": 5.178211163416274,
      "grad_norm": 0.06750312447547913,
      "learning_rate": 3.7059515803631475e-05,
      "loss": 0.0259,
      "step": 15400
    },
    {
      "epoch": 5.211835911230666,
      "grad_norm": 0.08562342077493668,
      "learning_rate": 3.6975453934095496e-05,
      "loss": 0.0266,
      "step": 15500
    },
    {
      "epoch": 5.211835911230666,
      "eval_loss": 0.026119783520698547,
      "eval_runtime": 2193.0042,
      "eval_samples_per_second": 1.877,
      "eval_steps_per_second": 0.47,
      "step": 15500
    },
    {
      "epoch": 5.245460659045057,
      "grad_norm": 0.09429838508367538,
      "learning_rate": 3.689139206455952e-05,
      "loss": 0.0263,
      "step": 15600
    },
    {
      "epoch": 5.279085406859449,
      "grad_norm": 0.0883929654955864,
      "learning_rate": 3.680733019502354e-05,
      "loss": 0.0252,
      "step": 15700
    },
    {
      "epoch": 5.31271015467384,
      "grad_norm": 0.10006888210773468,
      "learning_rate": 3.6723268325487555e-05,
      "loss": 0.0269,
      "step": 15800
    },
    {
      "epoch": 5.346334902488231,
      "grad_norm": 0.10586487501859665,
      "learning_rate": 3.663920645595158e-05,
      "loss": 0.0256,
      "step": 15900
    },
    {
      "epoch": 5.379959650302623,
      "grad_norm": 0.06341621279716492,
      "learning_rate": 3.65551445864156e-05,
      "loss": 0.025,
      "step": 16000
    },
    {
      "epoch": 5.379959650302623,
      "eval_loss": 0.026363592594861984,
      "eval_runtime": 2192.7734,
      "eval_samples_per_second": 1.878,
      "eval_steps_per_second": 0.47,
      "step": 16000
    },
    {
      "epoch": 5.413584398117014,
      "grad_norm": 0.06523071974515915,
      "learning_rate": 3.647108271687962e-05,
      "loss": 0.0263,
      "step": 16100
    },
    {
      "epoch": 5.447209145931406,
      "grad_norm": 0.08424317091703415,
      "learning_rate": 3.638702084734364e-05,
      "loss": 0.0255,
      "step": 16200
    },
    {
      "epoch": 5.480833893745797,
      "grad_norm": 0.10497578978538513,
      "learning_rate": 3.6302958977807665e-05,
      "loss": 0.0261,
      "step": 16300
    },
    {
      "epoch": 5.514458641560188,
      "grad_norm": 0.07165554165840149,
      "learning_rate": 3.6218897108271687e-05,
      "loss": 0.0258,
      "step": 16400
    },
    {
      "epoch": 5.54808338937458,
      "grad_norm": 0.08134083449840546,
      "learning_rate": 3.613483523873571e-05,
      "loss": 0.0259,
      "step": 16500
    },
    {
      "epoch": 5.54808338937458,
      "eval_loss": 0.026298971846699715,
      "eval_runtime": 2192.6784,
      "eval_samples_per_second": 1.878,
      "eval_steps_per_second": 0.47,
      "step": 16500
    },
    {
      "epoch": 5.581708137188971,
      "grad_norm": 0.06991230696439743,
      "learning_rate": 3.605077336919973e-05,
      "loss": 0.0265,
      "step": 16600
    },
    {
      "epoch": 5.615332885003363,
      "grad_norm": 0.08869428932666779,
      "learning_rate": 3.596671149966375e-05,
      "loss": 0.0265,
      "step": 16700
    },
    {
      "epoch": 5.648957632817754,
      "grad_norm": 0.08823204040527344,
      "learning_rate": 3.5882649630127774e-05,
      "loss": 0.0245,
      "step": 16800
    },
    {
      "epoch": 5.682582380632145,
      "grad_norm": 0.06886277347803116,
      "learning_rate": 3.5798587760591796e-05,
      "loss": 0.0275,
      "step": 16900
    },
    {
      "epoch": 5.716207128446537,
      "grad_norm": 0.15862633287906647,
      "learning_rate": 3.571452589105582e-05,
      "loss": 0.0265,
      "step": 17000
    },
    {
      "epoch": 5.716207128446537,
      "eval_loss": 0.0260801799595356,
      "eval_runtime": 2193.0645,
      "eval_samples_per_second": 1.877,
      "eval_steps_per_second": 0.47,
      "step": 17000
    },
    {
      "epoch": 5.749831876260928,
      "grad_norm": 0.08971567451953888,
      "learning_rate": 3.563046402151984e-05,
      "loss": 0.0262,
      "step": 17100
    },
    {
      "epoch": 5.78345662407532,
      "grad_norm": 0.0912289246916771,
      "learning_rate": 3.554640215198386e-05,
      "loss": 0.0263,
      "step": 17200
    },
    {
      "epoch": 5.817081371889711,
      "grad_norm": 0.08394849300384521,
      "learning_rate": 3.5462340282447883e-05,
      "loss": 0.0251,
      "step": 17300
    },
    {
      "epoch": 5.850706119704102,
      "grad_norm": 0.0846339538693428,
      "learning_rate": 3.5378278412911905e-05,
      "loss": 0.0264,
      "step": 17400
    },
    {
      "epoch": 5.884330867518494,
      "grad_norm": 0.06004859507083893,
      "learning_rate": 3.529421654337593e-05,
      "loss": 0.0259,
      "step": 17500
    },
    {
      "epoch": 5.884330867518494,
      "eval_loss": 0.026009295135736465,
      "eval_runtime": 2192.7751,
      "eval_samples_per_second": 1.878,
      "eval_steps_per_second": 0.47,
      "step": 17500
    },
    {
      "epoch": 5.917955615332885,
      "grad_norm": 0.0813107043504715,
      "learning_rate": 3.521015467383995e-05,
      "loss": 0.0262,
      "step": 17600
    },
    {
      "epoch": 5.951580363147277,
      "grad_norm": 0.08394074440002441,
      "learning_rate": 3.5126092804303964e-05,
      "loss": 0.0266,
      "step": 17700
    },
    {
      "epoch": 5.985205110961668,
      "grad_norm": 0.07671923190355301,
      "learning_rate": 3.5042030934767986e-05,
      "loss": 0.0258,
      "step": 17800
    },
    {
      "epoch": 6.018829858776059,
      "grad_norm": 0.08090254664421082,
      "learning_rate": 3.495796906523201e-05,
      "loss": 0.0255,
      "step": 17900
    },
    {
      "epoch": 6.052454606590451,
      "grad_norm": 0.08251045644283295,
      "learning_rate": 3.487390719569603e-05,
      "loss": 0.0267,
      "step": 18000
    },
    {
      "epoch": 6.052454606590451,
      "eval_loss": 0.02621583454310894,
      "eval_runtime": 2191.3826,
      "eval_samples_per_second": 1.879,
      "eval_steps_per_second": 0.47,
      "step": 18000
    },
    {
      "epoch": 6.086079354404842,
      "grad_norm": 0.07443496584892273,
      "learning_rate": 3.478984532616005e-05,
      "loss": 0.026,
      "step": 18100
    },
    {
      "epoch": 6.1197041022192336,
      "grad_norm": 0.06739948689937592,
      "learning_rate": 3.4705783456624073e-05,
      "loss": 0.0271,
      "step": 18200
    },
    {
      "epoch": 6.153328850033625,
      "grad_norm": 0.08195744454860687,
      "learning_rate": 3.4621721587088095e-05,
      "loss": 0.0251,
      "step": 18300
    },
    {
      "epoch": 6.186953597848016,
      "grad_norm": 0.10316330939531326,
      "learning_rate": 3.453765971755212e-05,
      "loss": 0.0264,
      "step": 18400
    },
    {
      "epoch": 6.220578345662408,
      "grad_norm": 0.056024979799985886,
      "learning_rate": 3.445359784801614e-05,
      "loss": 0.0262,
      "step": 18500
    },
    {
      "epoch": 6.220578345662408,
      "eval_loss": 0.026049107313156128,
      "eval_runtime": 2191.8685,
      "eval_samples_per_second": 1.878,
      "eval_steps_per_second": 0.47,
      "step": 18500
    },
    {
      "epoch": 6.254203093476799,
      "grad_norm": 0.09468795359134674,
      "learning_rate": 3.436953597848016e-05,
      "loss": 0.026,
      "step": 18600
    },
    {
      "epoch": 6.2878278412911905,
      "grad_norm": 0.11617095023393631,
      "learning_rate": 3.428547410894418e-05,
      "loss": 0.0264,
      "step": 18700
    },
    {
      "epoch": 6.321452589105582,
      "grad_norm": 0.09715243428945541,
      "learning_rate": 3.4201412239408205e-05,
      "loss": 0.0249,
      "step": 18800
    },
    {
      "epoch": 6.355077336919973,
      "grad_norm": 0.06806828081607819,
      "learning_rate": 3.4117350369872227e-05,
      "loss": 0.0262,
      "step": 18900
    },
    {
      "epoch": 6.388702084734365,
      "grad_norm": 0.0927310362458229,
      "learning_rate": 3.403328850033625e-05,
      "loss": 0.0256,
      "step": 19000
    },
    {
      "epoch": 6.388702084734365,
      "eval_loss": 0.025996843352913857,
      "eval_runtime": 2191.9597,
      "eval_samples_per_second": 1.878,
      "eval_steps_per_second": 0.47,
      "step": 19000
    },
    {
      "epoch": 6.422326832548756,
      "grad_norm": 0.058087799698114395,
      "learning_rate": 3.394922663080027e-05,
      "loss": 0.0264,
      "step": 19100
    },
    {
      "epoch": 6.4559515803631475,
      "grad_norm": 0.09581999480724335,
      "learning_rate": 3.386516476126429e-05,
      "loss": 0.0259,
      "step": 19200
    },
    {
      "epoch": 6.489576328177539,
      "grad_norm": 0.06734095513820648,
      "learning_rate": 3.3781102891728314e-05,
      "loss": 0.0265,
      "step": 19300
    },
    {
      "epoch": 6.52320107599193,
      "grad_norm": 0.07468601316213608,
      "learning_rate": 3.3697041022192336e-05,
      "loss": 0.0261,
      "step": 19400
    },
    {
      "epoch": 6.556825823806322,
      "grad_norm": 0.11808483302593231,
      "learning_rate": 3.361297915265635e-05,
      "loss": 0.026,
      "step": 19500
    },
    {
      "epoch": 6.556825823806322,
      "eval_loss": 0.026022331789135933,
      "eval_runtime": 2192.3071,
      "eval_samples_per_second": 1.878,
      "eval_steps_per_second": 0.47,
      "step": 19500
    },
    {
      "epoch": 6.590450571620713,
      "grad_norm": 0.09825644642114639,
      "learning_rate": 3.352891728312037e-05,
      "loss": 0.0256,
      "step": 19600
    },
    {
      "epoch": 6.6240753194351045,
      "grad_norm": 0.08229400217533112,
      "learning_rate": 3.3444855413584395e-05,
      "loss": 0.0256,
      "step": 19700
    },
    {
      "epoch": 6.657700067249496,
      "grad_norm": 0.09454414993524551,
      "learning_rate": 3.336079354404842e-05,
      "loss": 0.0255,
      "step": 19800
    },
    {
      "epoch": 6.691324815063887,
      "grad_norm": 0.08692110329866409,
      "learning_rate": 3.327673167451244e-05,
      "loss": 0.0269,
      "step": 19900
    },
    {
      "epoch": 6.724949562878279,
      "grad_norm": 0.06662362068891525,
      "learning_rate": 3.319266980497646e-05,
      "loss": 0.0271,
      "step": 20000
    },
    {
      "epoch": 6.724949562878279,
      "eval_loss": 0.026117658242583275,
      "eval_runtime": 2192.1317,
      "eval_samples_per_second": 1.878,
      "eval_steps_per_second": 0.47,
      "step": 20000
    },
    {
      "epoch": 6.75857431069267,
      "grad_norm": 0.07902657240629196,
      "learning_rate": 3.310860793544048e-05,
      "loss": 0.0264,
      "step": 20100
    },
    {
      "epoch": 6.7921990585070615,
      "grad_norm": 0.06244206055998802,
      "learning_rate": 3.3024546065904504e-05,
      "loss": 0.0258,
      "step": 20200
    },
    {
      "epoch": 6.825823806321453,
      "grad_norm": 0.0759262815117836,
      "learning_rate": 3.2940484196368526e-05,
      "loss": 0.0252,
      "step": 20300
    },
    {
      "epoch": 6.859448554135844,
      "grad_norm": 0.069956474006176,
      "learning_rate": 3.285642232683255e-05,
      "loss": 0.0257,
      "step": 20400
    },
    {
      "epoch": 6.893073301950236,
      "grad_norm": 0.06985242664813995,
      "learning_rate": 3.277236045729657e-05,
      "loss": 0.0261,
      "step": 20500
    },
    {
      "epoch": 6.893073301950236,
      "eval_loss": 0.026135563850402832,
      "eval_runtime": 2192.4731,
      "eval_samples_per_second": 1.878,
      "eval_steps_per_second": 0.47,
      "step": 20500
    },
    {
      "epoch": 6.926698049764627,
      "grad_norm": 0.06976001709699631,
      "learning_rate": 3.268829858776059e-05,
      "loss": 0.0258,
      "step": 20600
    },
    {
      "epoch": 6.9603227975790185,
      "grad_norm": 0.08801168203353882,
      "learning_rate": 3.2604236718224614e-05,
      "loss": 0.0255,
      "step": 20700
    },
    {
      "epoch": 6.99394754539341,
      "grad_norm": 0.07720479369163513,
      "learning_rate": 3.2520174848688635e-05,
      "loss": 0.0264,
      "step": 20800
    },
    {
      "epoch": 7.027572293207801,
      "grad_norm": 0.05034599453210831,
      "learning_rate": 3.243695359784802e-05,
      "loss": 0.0257,
      "step": 20900
    },
    {
      "epoch": 7.061197041022193,
      "grad_norm": 0.08875048160552979,
      "learning_rate": 3.235289172831204e-05,
      "loss": 0.0259,
      "step": 21000
    },
    {
      "epoch": 7.061197041022193,
      "eval_loss": 0.026247592642903328,
      "eval_runtime": 2192.4433,
      "eval_samples_per_second": 1.878,
      "eval_steps_per_second": 0.47,
      "step": 21000
    },
    {
      "epoch": 7.094821788836584,
      "grad_norm": 0.06600851565599442,
      "learning_rate": 3.226882985877606e-05,
      "loss": 0.0259,
      "step": 21100
    },
    {
      "epoch": 7.1284465366509755,
      "grad_norm": 0.08192308992147446,
      "learning_rate": 3.218476798924008e-05,
      "loss": 0.0253,
      "step": 21200
    },
    {
      "epoch": 7.162071284465367,
      "grad_norm": 0.11027104407548904,
      "learning_rate": 3.2100706119704104e-05,
      "loss": 0.0256,
      "step": 21300
    },
    {
      "epoch": 7.195696032279758,
      "grad_norm": 0.10389240831136703,
      "learning_rate": 3.2016644250168126e-05,
      "loss": 0.0268,
      "step": 21400
    },
    {
      "epoch": 7.22932078009415,
      "grad_norm": 0.09175025671720505,
      "learning_rate": 3.193258238063215e-05,
      "loss": 0.0263,
      "step": 21500
    },
    {
      "epoch": 7.22932078009415,
      "eval_loss": 0.02595752850174904,
      "eval_runtime": 2192.4325,
      "eval_samples_per_second": 1.878,
      "eval_steps_per_second": 0.47,
      "step": 21500
    },
    {
      "epoch": 7.262945527908541,
      "grad_norm": 0.07398940622806549,
      "learning_rate": 3.184852051109617e-05,
      "loss": 0.0264,
      "step": 21600
    },
    {
      "epoch": 7.2965702757229325,
      "grad_norm": 0.05879095569252968,
      "learning_rate": 3.176445864156019e-05,
      "loss": 0.0258,
      "step": 21700
    },
    {
      "epoch": 7.330195023537324,
      "grad_norm": 0.08525281399488449,
      "learning_rate": 3.1680396772024214e-05,
      "loss": 0.026,
      "step": 21800
    },
    {
      "epoch": 7.363819771351714,
      "grad_norm": 0.06484848260879517,
      "learning_rate": 3.1596334902488236e-05,
      "loss": 0.0258,
      "step": 21900
    },
    {
      "epoch": 7.397444519166106,
      "grad_norm": 0.099481001496315,
      "learning_rate": 3.151227303295226e-05,
      "loss": 0.0259,
      "step": 22000
    },
    {
      "epoch": 7.397444519166106,
      "eval_loss": 0.025987181812524796,
      "eval_runtime": 2192.2913,
      "eval_samples_per_second": 1.878,
      "eval_steps_per_second": 0.47,
      "step": 22000
    },
    {
      "epoch": 7.431069266980497,
      "grad_norm": 0.06455925852060318,
      "learning_rate": 3.142821116341628e-05,
      "loss": 0.027,
      "step": 22100
    },
    {
      "epoch": 7.464694014794889,
      "grad_norm": 0.07310882210731506,
      "learning_rate": 3.13441492938803e-05,
      "loss": 0.0253,
      "step": 22200
    },
    {
      "epoch": 7.49831876260928,
      "grad_norm": 0.11087337881326675,
      "learning_rate": 3.126008742434432e-05,
      "loss": 0.0262,
      "step": 22300
    },
    {
      "epoch": 7.531943510423671,
      "grad_norm": 0.13211603462696075,
      "learning_rate": 3.117602555480834e-05,
      "loss": 0.0263,
      "step": 22400
    },
    {
      "epoch": 7.565568258238063,
      "grad_norm": 0.09755170345306396,
      "learning_rate": 3.109196368527236e-05,
      "loss": 0.0257,
      "step": 22500
    },
    {
      "epoch": 7.565568258238063,
      "eval_loss": 0.026061153039336205,
      "eval_runtime": 2192.4128,
      "eval_samples_per_second": 1.878,
      "eval_steps_per_second": 0.47,
      "step": 22500
    },
    {
      "epoch": 7.599193006052454,
      "grad_norm": 0.06375793367624283,
      "learning_rate": 3.100790181573638e-05,
      "loss": 0.026,
      "step": 22600
    },
    {
      "epoch": 7.632817753866846,
      "grad_norm": 0.06005784869194031,
      "learning_rate": 3.0923839946200404e-05,
      "loss": 0.0255,
      "step": 22700
    },
    {
      "epoch": 7.666442501681237,
      "grad_norm": 0.07167443633079529,
      "learning_rate": 3.0839778076664426e-05,
      "loss": 0.0256,
      "step": 22800
    },
    {
      "epoch": 7.700067249495628,
      "grad_norm": 0.07622850686311722,
      "learning_rate": 3.075655682582381e-05,
      "loss": 0.0264,
      "step": 22900
    },
    {
      "epoch": 7.73369199731002,
      "grad_norm": 0.0770643949508667,
      "learning_rate": 3.067249495628783e-05,
      "loss": 0.0264,
      "step": 23000
    },
    {
      "epoch": 7.73369199731002,
      "eval_loss": 0.026060929521918297,
      "eval_runtime": 2191.5026,
      "eval_samples_per_second": 1.879,
      "eval_steps_per_second": 0.47,
      "step": 23000
    }
  ],
  "logging_steps": 100,
  "max_steps": 59480,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 20,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 3.2724934979538125e+18,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
