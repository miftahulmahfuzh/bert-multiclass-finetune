{
  "best_metric": 0.02593841776251793,
  "best_model_checkpoint": "mistralai/Mistral-Nemo-Instruct-2407_20250127_133602/checkpoint-11500",
  "epoch": 3.86684599865501,
  "eval_steps": 500,
  "global_step": 11500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.03362474781439139,
      "grad_norm": 0.641160786151886,
      "learning_rate": 4.992098184263618e-05,
      "loss": 1.1257,
      "step": 100
    },
    {
      "epoch": 0.06724949562878278,
      "grad_norm": 0.5001724362373352,
      "learning_rate": 4.9836919973100204e-05,
      "loss": 0.0342,
      "step": 200
    },
    {
      "epoch": 0.10087424344317418,
      "grad_norm": 0.27108579874038696,
      "learning_rate": 4.9752858103564226e-05,
      "loss": 0.0283,
      "step": 300
    },
    {
      "epoch": 0.13449899125756556,
      "grad_norm": 0.3886866569519043,
      "learning_rate": 4.966879623402825e-05,
      "loss": 0.0287,
      "step": 400
    },
    {
      "epoch": 0.16812373907195696,
      "grad_norm": 0.2577661871910095,
      "learning_rate": 4.958473436449227e-05,
      "loss": 0.0277,
      "step": 500
    },
    {
      "epoch": 0.16812373907195696,
      "eval_loss": 0.027763938531279564,
      "eval_runtime": 2192.4653,
      "eval_samples_per_second": 1.878,
      "eval_steps_per_second": 0.47,
      "step": 500
    },
    {
      "epoch": 0.20174848688634836,
      "grad_norm": 0.23048444092273712,
      "learning_rate": 4.950067249495629e-05,
      "loss": 0.0268,
      "step": 600
    },
    {
      "epoch": 0.23537323470073973,
      "grad_norm": 0.19538654386997223,
      "learning_rate": 4.941661062542031e-05,
      "loss": 0.0277,
      "step": 700
    },
    {
      "epoch": 0.26899798251513113,
      "grad_norm": 0.2090679258108139,
      "learning_rate": 4.9332548755884335e-05,
      "loss": 0.0269,
      "step": 800
    },
    {
      "epoch": 0.3026227303295225,
      "grad_norm": 0.3309393525123596,
      "learning_rate": 4.924848688634836e-05,
      "loss": 0.0274,
      "step": 900
    },
    {
      "epoch": 0.3362474781439139,
      "grad_norm": 0.19589494168758392,
      "learning_rate": 4.916442501681238e-05,
      "loss": 0.0278,
      "step": 1000
    },
    {
      "epoch": 0.3362474781439139,
      "eval_loss": 0.027354568243026733,
      "eval_runtime": 2192.4732,
      "eval_samples_per_second": 1.878,
      "eval_steps_per_second": 0.47,
      "step": 1000
    },
    {
      "epoch": 0.3698722259583053,
      "grad_norm": 0.20498301088809967,
      "learning_rate": 4.90803631472764e-05,
      "loss": 0.0264,
      "step": 1100
    },
    {
      "epoch": 0.4034969737726967,
      "grad_norm": 0.19685626029968262,
      "learning_rate": 4.899630127774042e-05,
      "loss": 0.0269,
      "step": 1200
    },
    {
      "epoch": 0.4371217215870881,
      "grad_norm": 0.29373177886009216,
      "learning_rate": 4.891223940820444e-05,
      "loss": 0.0282,
      "step": 1300
    },
    {
      "epoch": 0.47074646940147946,
      "grad_norm": 0.19394412636756897,
      "learning_rate": 4.882817753866846e-05,
      "loss": 0.0266,
      "step": 1400
    },
    {
      "epoch": 0.5043712172158709,
      "grad_norm": 0.29366353154182434,
      "learning_rate": 4.874411566913248e-05,
      "loss": 0.0263,
      "step": 1500
    },
    {
      "epoch": 0.5043712172158709,
      "eval_loss": 0.02684774063527584,
      "eval_runtime": 2192.7246,
      "eval_samples_per_second": 1.878,
      "eval_steps_per_second": 0.47,
      "step": 1500
    },
    {
      "epoch": 0.5379959650302623,
      "grad_norm": 0.1639816164970398,
      "learning_rate": 4.8660053799596503e-05,
      "loss": 0.0265,
      "step": 1600
    },
    {
      "epoch": 0.5716207128446537,
      "grad_norm": 0.11305760592222214,
      "learning_rate": 4.8575991930060525e-05,
      "loss": 0.0269,
      "step": 1700
    },
    {
      "epoch": 0.605245460659045,
      "grad_norm": 0.1909124255180359,
      "learning_rate": 4.849193006052455e-05,
      "loss": 0.0272,
      "step": 1800
    },
    {
      "epoch": 0.6388702084734365,
      "grad_norm": 0.23782534897327423,
      "learning_rate": 4.840786819098857e-05,
      "loss": 0.0275,
      "step": 1900
    },
    {
      "epoch": 0.6724949562878278,
      "grad_norm": 0.1830664575099945,
      "learning_rate": 4.832380632145259e-05,
      "loss": 0.027,
      "step": 2000
    },
    {
      "epoch": 0.6724949562878278,
      "eval_loss": 0.026575947180390358,
      "eval_runtime": 2192.3383,
      "eval_samples_per_second": 1.878,
      "eval_steps_per_second": 0.47,
      "step": 2000
    },
    {
      "epoch": 0.7061197041022192,
      "grad_norm": 0.2677260637283325,
      "learning_rate": 4.823974445191661e-05,
      "loss": 0.0264,
      "step": 2100
    },
    {
      "epoch": 0.7397444519166106,
      "grad_norm": 0.2206425815820694,
      "learning_rate": 4.8155682582380635e-05,
      "loss": 0.027,
      "step": 2200
    },
    {
      "epoch": 0.773369199731002,
      "grad_norm": 0.15970540046691895,
      "learning_rate": 4.8071620712844657e-05,
      "loss": 0.0263,
      "step": 2300
    },
    {
      "epoch": 0.8069939475453934,
      "grad_norm": 0.17991675436496735,
      "learning_rate": 4.798755884330868e-05,
      "loss": 0.0275,
      "step": 2400
    },
    {
      "epoch": 0.8406186953597848,
      "grad_norm": 0.1285300850868225,
      "learning_rate": 4.79034969737727e-05,
      "loss": 0.0263,
      "step": 2500
    },
    {
      "epoch": 0.8406186953597848,
      "eval_loss": 0.027360089123249054,
      "eval_runtime": 2192.4003,
      "eval_samples_per_second": 1.878,
      "eval_steps_per_second": 0.47,
      "step": 2500
    },
    {
      "epoch": 0.8742434431741762,
      "grad_norm": 0.12165194004774094,
      "learning_rate": 4.781943510423672e-05,
      "loss": 0.0268,
      "step": 2600
    },
    {
      "epoch": 0.9078681909885676,
      "grad_norm": 0.1593778431415558,
      "learning_rate": 4.7735373234700744e-05,
      "loss": 0.0263,
      "step": 2700
    },
    {
      "epoch": 0.9414929388029589,
      "grad_norm": 0.23292545974254608,
      "learning_rate": 4.7651311365164766e-05,
      "loss": 0.0271,
      "step": 2800
    },
    {
      "epoch": 0.9751176866173503,
      "grad_norm": 0.10912999510765076,
      "learning_rate": 4.756724949562879e-05,
      "loss": 0.0272,
      "step": 2900
    },
    {
      "epoch": 1.0087424344317417,
      "grad_norm": 0.1429692804813385,
      "learning_rate": 4.748318762609281e-05,
      "loss": 0.0265,
      "step": 3000
    },
    {
      "epoch": 1.0087424344317417,
      "eval_loss": 0.026500597596168518,
      "eval_runtime": 2191.8529,
      "eval_samples_per_second": 1.878,
      "eval_steps_per_second": 0.47,
      "step": 3000
    },
    {
      "epoch": 1.0423671822461331,
      "grad_norm": 0.20607545971870422,
      "learning_rate": 4.7399125756556825e-05,
      "loss": 0.0275,
      "step": 3100
    },
    {
      "epoch": 1.0759919300605245,
      "grad_norm": 0.1046142429113388,
      "learning_rate": 4.731506388702085e-05,
      "loss": 0.0264,
      "step": 3200
    },
    {
      "epoch": 1.109616677874916,
      "grad_norm": 0.21291977167129517,
      "learning_rate": 4.723100201748487e-05,
      "loss": 0.0274,
      "step": 3300
    },
    {
      "epoch": 1.1432414256893073,
      "grad_norm": 0.12833045423030853,
      "learning_rate": 4.714694014794889e-05,
      "loss": 0.0261,
      "step": 3400
    },
    {
      "epoch": 1.1768661735036987,
      "grad_norm": 0.13565319776535034,
      "learning_rate": 4.706287827841291e-05,
      "loss": 0.0262,
      "step": 3500
    },
    {
      "epoch": 1.1768661735036987,
      "eval_loss": 0.026306092739105225,
      "eval_runtime": 2192.3688,
      "eval_samples_per_second": 1.878,
      "eval_steps_per_second": 0.47,
      "step": 3500
    },
    {
      "epoch": 1.21049092131809,
      "grad_norm": 0.14196908473968506,
      "learning_rate": 4.6978816408876934e-05,
      "loss": 0.0265,
      "step": 3600
    },
    {
      "epoch": 1.2441156691324815,
      "grad_norm": 0.21494944393634796,
      "learning_rate": 4.6894754539340956e-05,
      "loss": 0.0268,
      "step": 3700
    },
    {
      "epoch": 1.277740416946873,
      "grad_norm": 0.18145109713077545,
      "learning_rate": 4.681069266980498e-05,
      "loss": 0.0269,
      "step": 3800
    },
    {
      "epoch": 1.3113651647612643,
      "grad_norm": 0.1316331923007965,
      "learning_rate": 4.6726630800269e-05,
      "loss": 0.0262,
      "step": 3900
    },
    {
      "epoch": 1.3449899125756557,
      "grad_norm": 0.18663345277309418,
      "learning_rate": 4.664256893073302e-05,
      "loss": 0.0272,
      "step": 4000
    },
    {
      "epoch": 1.3449899125756557,
      "eval_loss": 0.0264876838773489,
      "eval_runtime": 2192.4351,
      "eval_samples_per_second": 1.878,
      "eval_steps_per_second": 0.47,
      "step": 4000
    },
    {
      "epoch": 1.378614660390047,
      "grad_norm": 0.1402311474084854,
      "learning_rate": 4.6558507061197044e-05,
      "loss": 0.0252,
      "step": 4100
    },
    {
      "epoch": 1.4122394082044385,
      "grad_norm": 0.07758776098489761,
      "learning_rate": 4.6474445191661065e-05,
      "loss": 0.0265,
      "step": 4200
    },
    {
      "epoch": 1.44586415601883,
      "grad_norm": 0.1768583506345749,
      "learning_rate": 4.639038332212509e-05,
      "loss": 0.0278,
      "step": 4300
    },
    {
      "epoch": 1.4794889038332213,
      "grad_norm": 0.12287817895412445,
      "learning_rate": 4.630632145258911e-05,
      "loss": 0.0253,
      "step": 4400
    },
    {
      "epoch": 1.5131136516476127,
      "grad_norm": 0.1156153529882431,
      "learning_rate": 4.622225958305313e-05,
      "loss": 0.0275,
      "step": 4500
    },
    {
      "epoch": 1.5131136516476127,
      "eval_loss": 0.026322519406676292,
      "eval_runtime": 2191.9651,
      "eval_samples_per_second": 1.878,
      "eval_steps_per_second": 0.47,
      "step": 4500
    },
    {
      "epoch": 1.546738399462004,
      "grad_norm": 0.23380689322948456,
      "learning_rate": 4.613819771351715e-05,
      "loss": 0.0259,
      "step": 4600
    },
    {
      "epoch": 1.5803631472763953,
      "grad_norm": 0.13502661883831024,
      "learning_rate": 4.6054135843981175e-05,
      "loss": 0.0264,
      "step": 4700
    },
    {
      "epoch": 1.6139878950907867,
      "grad_norm": 0.10481362789869308,
      "learning_rate": 4.59700739744452e-05,
      "loss": 0.0265,
      "step": 4800
    },
    {
      "epoch": 1.647612642905178,
      "grad_norm": 0.14020827412605286,
      "learning_rate": 4.588601210490921e-05,
      "loss": 0.0257,
      "step": 4900
    },
    {
      "epoch": 1.6812373907195695,
      "grad_norm": 0.11887529492378235,
      "learning_rate": 4.5801950235373234e-05,
      "loss": 0.0255,
      "step": 5000
    },
    {
      "epoch": 1.6812373907195695,
      "eval_loss": 0.026661477982997894,
      "eval_runtime": 2192.8148,
      "eval_samples_per_second": 1.877,
      "eval_steps_per_second": 0.47,
      "step": 5000
    },
    {
      "epoch": 1.7148621385339609,
      "grad_norm": 0.14070995151996613,
      "learning_rate": 4.5717888365837255e-05,
      "loss": 0.0255,
      "step": 5100
    },
    {
      "epoch": 1.7484868863483523,
      "grad_norm": 0.09499962627887726,
      "learning_rate": 4.563382649630128e-05,
      "loss": 0.0266,
      "step": 5200
    },
    {
      "epoch": 1.7821116341627437,
      "grad_norm": 0.13643738627433777,
      "learning_rate": 4.55497646267653e-05,
      "loss": 0.0271,
      "step": 5300
    },
    {
      "epoch": 1.815736381977135,
      "grad_norm": 0.12008057534694672,
      "learning_rate": 4.546570275722932e-05,
      "loss": 0.0269,
      "step": 5400
    },
    {
      "epoch": 1.8493611297915264,
      "grad_norm": 0.10218573361635208,
      "learning_rate": 4.538164088769334e-05,
      "loss": 0.0276,
      "step": 5500
    },
    {
      "epoch": 1.8493611297915264,
      "eval_loss": 0.026569955050945282,
      "eval_runtime": 2192.2533,
      "eval_samples_per_second": 1.878,
      "eval_steps_per_second": 0.47,
      "step": 5500
    },
    {
      "epoch": 1.8829858776059178,
      "grad_norm": 0.1134338527917862,
      "learning_rate": 4.5297579018157365e-05,
      "loss": 0.0267,
      "step": 5600
    },
    {
      "epoch": 1.9166106254203092,
      "grad_norm": 0.0923151969909668,
      "learning_rate": 4.521351714862139e-05,
      "loss": 0.0265,
      "step": 5700
    },
    {
      "epoch": 1.9502353732347006,
      "grad_norm": 0.09816635400056839,
      "learning_rate": 4.512945527908541e-05,
      "loss": 0.026,
      "step": 5800
    },
    {
      "epoch": 1.983860121049092,
      "grad_norm": 0.11389204114675522,
      "learning_rate": 4.504539340954943e-05,
      "loss": 0.0276,
      "step": 5900
    },
    {
      "epoch": 2.0174848688634834,
      "grad_norm": 0.07684340327978134,
      "learning_rate": 4.496133154001345e-05,
      "loss": 0.0265,
      "step": 6000
    },
    {
      "epoch": 2.0174848688634834,
      "eval_loss": 0.026240721344947815,
      "eval_runtime": 2192.4228,
      "eval_samples_per_second": 1.878,
      "eval_steps_per_second": 0.47,
      "step": 6000
    },
    {
      "epoch": 2.051109616677875,
      "grad_norm": 0.10372278094291687,
      "learning_rate": 4.4877269670477474e-05,
      "loss": 0.0269,
      "step": 6100
    },
    {
      "epoch": 2.0847343644922662,
      "grad_norm": 0.12303819507360458,
      "learning_rate": 4.4793207800941496e-05,
      "loss": 0.0255,
      "step": 6200
    },
    {
      "epoch": 2.1183591123066576,
      "grad_norm": 0.12709005177021027,
      "learning_rate": 4.470914593140552e-05,
      "loss": 0.0258,
      "step": 6300
    },
    {
      "epoch": 2.151983860121049,
      "grad_norm": 0.07869327813386917,
      "learning_rate": 4.462508406186954e-05,
      "loss": 0.0262,
      "step": 6400
    },
    {
      "epoch": 2.1856086079354404,
      "grad_norm": 0.17674118280410767,
      "learning_rate": 4.454102219233356e-05,
      "loss": 0.026,
      "step": 6500
    },
    {
      "epoch": 2.1856086079354404,
      "eval_loss": 0.026347648352384567,
      "eval_runtime": 2192.9052,
      "eval_samples_per_second": 1.877,
      "eval_steps_per_second": 0.47,
      "step": 6500
    },
    {
      "epoch": 2.219233355749832,
      "grad_norm": 0.113501638174057,
      "learning_rate": 4.4456960322797584e-05,
      "loss": 0.0266,
      "step": 6600
    },
    {
      "epoch": 2.2528581035642232,
      "grad_norm": 0.09660324454307556,
      "learning_rate": 4.4372898453261605e-05,
      "loss": 0.0268,
      "step": 6700
    },
    {
      "epoch": 2.2864828513786146,
      "grad_norm": 0.11121663451194763,
      "learning_rate": 4.428883658372562e-05,
      "loss": 0.0266,
      "step": 6800
    },
    {
      "epoch": 2.320107599193006,
      "grad_norm": 0.07921332865953445,
      "learning_rate": 4.420477471418964e-05,
      "loss": 0.0271,
      "step": 6900
    },
    {
      "epoch": 2.3537323470073974,
      "grad_norm": 0.07500557601451874,
      "learning_rate": 4.4120712844653664e-05,
      "loss": 0.0275,
      "step": 7000
    },
    {
      "epoch": 2.3537323470073974,
      "eval_loss": 0.026391208171844482,
      "eval_runtime": 2192.5273,
      "eval_samples_per_second": 1.878,
      "eval_steps_per_second": 0.47,
      "step": 7000
    },
    {
      "epoch": 2.387357094821789,
      "grad_norm": 0.09904318302869797,
      "learning_rate": 4.4036650975117686e-05,
      "loss": 0.0267,
      "step": 7100
    },
    {
      "epoch": 2.42098184263618,
      "grad_norm": 0.09968884289264679,
      "learning_rate": 4.395258910558171e-05,
      "loss": 0.026,
      "step": 7200
    },
    {
      "epoch": 2.4546065904505716,
      "grad_norm": 0.1820349544286728,
      "learning_rate": 4.386852723604573e-05,
      "loss": 0.0251,
      "step": 7300
    },
    {
      "epoch": 2.488231338264963,
      "grad_norm": 0.12551140785217285,
      "learning_rate": 4.378446536650975e-05,
      "loss": 0.0263,
      "step": 7400
    },
    {
      "epoch": 2.5218560860793544,
      "grad_norm": 0.17216499149799347,
      "learning_rate": 4.3700403496973774e-05,
      "loss": 0.0269,
      "step": 7500
    },
    {
      "epoch": 2.5218560860793544,
      "eval_loss": 0.02659681625664234,
      "eval_runtime": 2192.5104,
      "eval_samples_per_second": 1.878,
      "eval_steps_per_second": 0.47,
      "step": 7500
    },
    {
      "epoch": 2.555480833893746,
      "grad_norm": 0.0723830834031105,
      "learning_rate": 4.3616341627437796e-05,
      "loss": 0.0256,
      "step": 7600
    },
    {
      "epoch": 2.589105581708137,
      "grad_norm": 0.11468777060508728,
      "learning_rate": 4.353227975790182e-05,
      "loss": 0.0268,
      "step": 7700
    },
    {
      "epoch": 2.6227303295225286,
      "grad_norm": 0.13840582966804504,
      "learning_rate": 4.344821788836584e-05,
      "loss": 0.0251,
      "step": 7800
    },
    {
      "epoch": 2.65635507733692,
      "grad_norm": 0.10273584723472595,
      "learning_rate": 4.336415601882986e-05,
      "loss": 0.027,
      "step": 7900
    },
    {
      "epoch": 2.6899798251513114,
      "grad_norm": 0.09140454232692719,
      "learning_rate": 4.328009414929388e-05,
      "loss": 0.0262,
      "step": 8000
    },
    {
      "epoch": 2.6899798251513114,
      "eval_loss": 0.026367973536252975,
      "eval_runtime": 2192.0391,
      "eval_samples_per_second": 1.878,
      "eval_steps_per_second": 0.47,
      "step": 8000
    },
    {
      "epoch": 2.723604572965703,
      "grad_norm": 0.11577794700860977,
      "learning_rate": 4.3196032279757905e-05,
      "loss": 0.0261,
      "step": 8100
    },
    {
      "epoch": 2.757229320780094,
      "grad_norm": 0.11418697983026505,
      "learning_rate": 4.311197041022193e-05,
      "loss": 0.0266,
      "step": 8200
    },
    {
      "epoch": 2.7908540685944856,
      "grad_norm": 0.10088880360126495,
      "learning_rate": 4.302790854068595e-05,
      "loss": 0.0259,
      "step": 8300
    },
    {
      "epoch": 2.824478816408877,
      "grad_norm": 0.09994824975728989,
      "learning_rate": 4.294384667114997e-05,
      "loss": 0.0255,
      "step": 8400
    },
    {
      "epoch": 2.8581035642232684,
      "grad_norm": 0.10596463084220886,
      "learning_rate": 4.285978480161399e-05,
      "loss": 0.0268,
      "step": 8500
    },
    {
      "epoch": 2.8581035642232684,
      "eval_loss": 0.026176907122135162,
      "eval_runtime": 2192.6522,
      "eval_samples_per_second": 1.878,
      "eval_steps_per_second": 0.47,
      "step": 8500
    },
    {
      "epoch": 2.89172831203766,
      "grad_norm": 0.08060269057750702,
      "learning_rate": 4.277572293207801e-05,
      "loss": 0.0262,
      "step": 8600
    },
    {
      "epoch": 2.925353059852051,
      "grad_norm": 0.10241471976041794,
      "learning_rate": 4.269166106254203e-05,
      "loss": 0.0269,
      "step": 8700
    },
    {
      "epoch": 2.9589778076664426,
      "grad_norm": 0.08059334754943848,
      "learning_rate": 4.260759919300605e-05,
      "loss": 0.027,
      "step": 8800
    },
    {
      "epoch": 2.992602555480834,
      "grad_norm": 0.11221513152122498,
      "learning_rate": 4.252353732347007e-05,
      "loss": 0.0254,
      "step": 8900
    },
    {
      "epoch": 3.0262273032952254,
      "grad_norm": 0.1491355001926422,
      "learning_rate": 4.2439475453934095e-05,
      "loss": 0.0265,
      "step": 9000
    },
    {
      "epoch": 3.0262273032952254,
      "eval_loss": 0.02625347673892975,
      "eval_runtime": 2192.6834,
      "eval_samples_per_second": 1.878,
      "eval_steps_per_second": 0.47,
      "step": 9000
    },
    {
      "epoch": 3.0598520511096168,
      "grad_norm": 0.07609028369188309,
      "learning_rate": 4.235541358439812e-05,
      "loss": 0.026,
      "step": 9100
    },
    {
      "epoch": 3.093476798924008,
      "grad_norm": 0.11626427620649338,
      "learning_rate": 4.227135171486214e-05,
      "loss": 0.0268,
      "step": 9200
    },
    {
      "epoch": 3.1271015467383996,
      "grad_norm": 0.09955122321844101,
      "learning_rate": 4.218728984532616e-05,
      "loss": 0.0268,
      "step": 9300
    },
    {
      "epoch": 3.160726294552791,
      "grad_norm": 0.09756293892860413,
      "learning_rate": 4.210322797579018e-05,
      "loss": 0.0263,
      "step": 9400
    },
    {
      "epoch": 3.1943510423671824,
      "grad_norm": 0.08513397723436356,
      "learning_rate": 4.2019166106254204e-05,
      "loss": 0.026,
      "step": 9500
    },
    {
      "epoch": 3.1943510423671824,
      "eval_loss": 0.026211341843008995,
      "eval_runtime": 2193.0541,
      "eval_samples_per_second": 1.877,
      "eval_steps_per_second": 0.47,
      "step": 9500
    },
    {
      "epoch": 3.2279757901815738,
      "grad_norm": 0.08176302909851074,
      "learning_rate": 4.1935104236718226e-05,
      "loss": 0.0262,
      "step": 9600
    },
    {
      "epoch": 3.261600537995965,
      "grad_norm": 0.1372072547674179,
      "learning_rate": 4.185104236718225e-05,
      "loss": 0.0271,
      "step": 9700
    },
    {
      "epoch": 3.2952252858103566,
      "grad_norm": 0.09025067090988159,
      "learning_rate": 4.176698049764627e-05,
      "loss": 0.0263,
      "step": 9800
    },
    {
      "epoch": 3.328850033624748,
      "grad_norm": 0.08269008249044418,
      "learning_rate": 4.168291862811029e-05,
      "loss": 0.0255,
      "step": 9900
    },
    {
      "epoch": 3.3624747814391394,
      "grad_norm": 0.13479496538639069,
      "learning_rate": 4.1598856758574314e-05,
      "loss": 0.0268,
      "step": 10000
    },
    {
      "epoch": 3.3624747814391394,
      "eval_loss": 0.026189744472503662,
      "eval_runtime": 2193.0213,
      "eval_samples_per_second": 1.877,
      "eval_steps_per_second": 0.47,
      "step": 10000
    },
    {
      "epoch": 3.3960995292535308,
      "grad_norm": 0.05816490203142166,
      "learning_rate": 4.1514794889038336e-05,
      "loss": 0.026,
      "step": 10100
    },
    {
      "epoch": 3.429724277067922,
      "grad_norm": 0.10785482078790665,
      "learning_rate": 4.143073301950236e-05,
      "loss": 0.0262,
      "step": 10200
    },
    {
      "epoch": 3.4633490248823136,
      "grad_norm": 0.10899050533771515,
      "learning_rate": 4.134667114996638e-05,
      "loss": 0.0267,
      "step": 10300
    },
    {
      "epoch": 3.496973772696705,
      "grad_norm": 0.10196287930011749,
      "learning_rate": 4.1262609280430394e-05,
      "loss": 0.0258,
      "step": 10400
    },
    {
      "epoch": 3.530598520511096,
      "grad_norm": 0.09878555685281754,
      "learning_rate": 4.1178547410894416e-05,
      "loss": 0.0256,
      "step": 10500
    },
    {
      "epoch": 3.530598520511096,
      "eval_loss": 0.02615259774029255,
      "eval_runtime": 2192.7299,
      "eval_samples_per_second": 1.878,
      "eval_steps_per_second": 0.47,
      "step": 10500
    },
    {
      "epoch": 3.5642232683254873,
      "grad_norm": 0.1127917692065239,
      "learning_rate": 4.109448554135844e-05,
      "loss": 0.026,
      "step": 10600
    },
    {
      "epoch": 3.5978480161398787,
      "grad_norm": 0.08391498774290085,
      "learning_rate": 4.101042367182246e-05,
      "loss": 0.0265,
      "step": 10700
    },
    {
      "epoch": 3.63147276395427,
      "grad_norm": 0.1638464629650116,
      "learning_rate": 4.092636180228648e-05,
      "loss": 0.0258,
      "step": 10800
    },
    {
      "epoch": 3.6650975117686615,
      "grad_norm": 0.07078135758638382,
      "learning_rate": 4.0842299932750504e-05,
      "loss": 0.0271,
      "step": 10900
    },
    {
      "epoch": 3.698722259583053,
      "grad_norm": 0.06283584982156754,
      "learning_rate": 4.0758238063214526e-05,
      "loss": 0.0259,
      "step": 11000
    },
    {
      "epoch": 3.698722259583053,
      "eval_loss": 0.026195673272013664,
      "eval_runtime": 2191.3667,
      "eval_samples_per_second": 1.879,
      "eval_steps_per_second": 0.47,
      "step": 11000
    },
    {
      "epoch": 3.7323470073974443,
      "grad_norm": 0.05980030447244644,
      "learning_rate": 4.067417619367855e-05,
      "loss": 0.0253,
      "step": 11100
    },
    {
      "epoch": 3.7659717552118357,
      "grad_norm": 0.08919291198253632,
      "learning_rate": 4.059011432414257e-05,
      "loss": 0.0266,
      "step": 11200
    },
    {
      "epoch": 3.799596503026227,
      "grad_norm": 0.11170770227909088,
      "learning_rate": 4.050605245460659e-05,
      "loss": 0.0258,
      "step": 11300
    },
    {
      "epoch": 3.8332212508406185,
      "grad_norm": 0.16678763926029205,
      "learning_rate": 4.042199058507061e-05,
      "loss": 0.0261,
      "step": 11400
    },
    {
      "epoch": 3.86684599865501,
      "grad_norm": 0.09004098922014236,
      "learning_rate": 4.0337928715534635e-05,
      "loss": 0.0264,
      "step": 11500
    },
    {
      "epoch": 3.86684599865501,
      "eval_loss": 0.02593841776251793,
      "eval_runtime": 2192.0582,
      "eval_samples_per_second": 1.878,
      "eval_steps_per_second": 0.47,
      "step": 11500
    }
  ],
  "logging_steps": 100,
  "max_steps": 59480,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 20,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.636300117030994e+18,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
